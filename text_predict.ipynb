{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_predict.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMzsRYMCoyGbbwDL2xaRG+H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StanleyLiangYork/NLP_deepLearning/blob/master/text_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E56_uWzJ0l8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzzgE6B50wE_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "93305bf8-ebf8-4baf-b354-86fa2c950d5c"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n",
            "263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW5QFtBZ05Jx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZC3yM8W1cgU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "1558ba72-42d9-4ba4-a69c-d0f5cc875848"
      },
      "source": [
        "print(tokenizer.word_index['in'])\n",
        "print(tokenizer.word_index['the'])\n",
        "print(tokenizer.word_index['town'])\n",
        "print(tokenizer.word_index['of'])\n",
        "print(tokenizer.word_index['athy'])\n",
        "print(tokenizer.word_index['one'])\n",
        "print(tokenizer.word_index['jeremy'])\n",
        "print(tokenizer.word_index['lanigan'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "2\n",
            "66\n",
            "8\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBGR3uP91kb_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "7d0425b9-cefa-4439-e7ff-64ebb9cdfc01"
      },
      "source": [
        "print(xs[6])\n",
        "print(ys[6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  4  2 66  8 67 68 69]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4uPJVed13CF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "f8efadfd-e66e-440e-f893-624f4faec545"
      },
      "source": [
        "print(xs[5])\n",
        "print(ys[5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  0  4  2 66  8 67 68]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMpucTQ62ORO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c7a69e6-cc45-4f66-e148-909a8d3096aa"
      },
      "source": [
        "  model = Sequential()\n",
        "  model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "  model.add(Bidirectional(LSTM(20)))\n",
        "  model.add(Dense(total_words, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  history = model.fit(xs, ys, epochs=500, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.5664 - accuracy: 0.0177\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.5354 - accuracy: 0.0530\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.4629 - accuracy: 0.0508\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.2864 - accuracy: 0.0508\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.1233 - accuracy: 0.0508\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.0718 - accuracy: 0.0552\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.0355 - accuracy: 0.0574\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.0056 - accuracy: 0.0530\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.9815 - accuracy: 0.0552\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.9494 - accuracy: 0.0508\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.9176 - accuracy: 0.0508\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.8810 - accuracy: 0.0618\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.8453 - accuracy: 0.0662\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.7982 - accuracy: 0.0596\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.7422 - accuracy: 0.0662\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.6874 - accuracy: 0.0706\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.6319 - accuracy: 0.0751\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.5832 - accuracy: 0.0706\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.5416 - accuracy: 0.0728\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.5098 - accuracy: 0.0861\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.4698 - accuracy: 0.0839\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.4183 - accuracy: 0.0751\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.3726 - accuracy: 0.0905\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.3289 - accuracy: 0.0839\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.2901 - accuracy: 0.0927\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.2484 - accuracy: 0.1015\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.1952 - accuracy: 0.0971\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.1508 - accuracy: 0.1258\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.1068 - accuracy: 0.1413\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.0529 - accuracy: 0.1479\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.0093 - accuracy: 0.1545\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.9580 - accuracy: 0.1589\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.9192 - accuracy: 0.1700\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.8779 - accuracy: 0.1810\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.8336 - accuracy: 0.1943\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.7771 - accuracy: 0.1921\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.7309 - accuracy: 0.2119\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.6791 - accuracy: 0.2031\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.6331 - accuracy: 0.2185\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.5910 - accuracy: 0.2362\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.5500 - accuracy: 0.2472\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.5100 - accuracy: 0.2494\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.4575 - accuracy: 0.2517\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.4186 - accuracy: 0.2605\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.3755 - accuracy: 0.2693\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.3302 - accuracy: 0.2936\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.3075 - accuracy: 0.2848\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.2615 - accuracy: 0.2892\n",
            "Epoch 49/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.2113 - accuracy: 0.2980\n",
            "Epoch 50/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.1752 - accuracy: 0.3289\n",
            "Epoch 51/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.1382 - accuracy: 0.3223\n",
            "Epoch 52/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.1013 - accuracy: 0.3510\n",
            "Epoch 53/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.0493 - accuracy: 0.3598\n",
            "Epoch 54/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.0031 - accuracy: 0.3819\n",
            "Epoch 55/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.9659 - accuracy: 0.3974\n",
            "Epoch 56/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.9181 - accuracy: 0.4216\n",
            "Epoch 57/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.8809 - accuracy: 0.4172\n",
            "Epoch 58/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.8338 - accuracy: 0.4172\n",
            "Epoch 59/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.7933 - accuracy: 0.4172\n",
            "Epoch 60/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.7594 - accuracy: 0.4216\n",
            "Epoch 61/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.7328 - accuracy: 0.4459\n",
            "Epoch 62/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.6961 - accuracy: 0.4481\n",
            "Epoch 63/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.6613 - accuracy: 0.4790\n",
            "Epoch 64/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.6402 - accuracy: 0.4879\n",
            "Epoch 65/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.6163 - accuracy: 0.4879\n",
            "Epoch 66/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.5843 - accuracy: 0.4989\n",
            "Epoch 67/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.5555 - accuracy: 0.4989\n",
            "Epoch 68/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.5187 - accuracy: 0.5232\n",
            "Epoch 69/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.4902 - accuracy: 0.5188\n",
            "Epoch 70/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.4548 - accuracy: 0.5254\n",
            "Epoch 71/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.4215 - accuracy: 0.5298\n",
            "Epoch 72/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.3724 - accuracy: 0.5453\n",
            "Epoch 73/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.3481 - accuracy: 0.5563\n",
            "Epoch 74/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.3186 - accuracy: 0.5629\n",
            "Epoch 75/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2723 - accuracy: 0.5982\n",
            "Epoch 76/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2456 - accuracy: 0.5894\n",
            "Epoch 77/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2198 - accuracy: 0.6093\n",
            "Epoch 78/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.1896 - accuracy: 0.5982\n",
            "Epoch 79/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1635 - accuracy: 0.6004\n",
            "Epoch 80/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.1362 - accuracy: 0.6093\n",
            "Epoch 81/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.1053 - accuracy: 0.6181\n",
            "Epoch 82/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.0967 - accuracy: 0.5982\n",
            "Epoch 83/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.0553 - accuracy: 0.6313\n",
            "Epoch 84/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.0399 - accuracy: 0.6402\n",
            "Epoch 85/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.0119 - accuracy: 0.6490\n",
            "Epoch 86/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.9938 - accuracy: 0.6490\n",
            "Epoch 87/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.9578 - accuracy: 0.6711\n",
            "Epoch 88/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.9384 - accuracy: 0.6645\n",
            "Epoch 89/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.9148 - accuracy: 0.6777\n",
            "Epoch 90/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8943 - accuracy: 0.6799\n",
            "Epoch 91/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8610 - accuracy: 0.6821\n",
            "Epoch 92/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8430 - accuracy: 0.6733\n",
            "Epoch 93/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.8174 - accuracy: 0.6821\n",
            "Epoch 94/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7832 - accuracy: 0.6887\n",
            "Epoch 95/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7521 - accuracy: 0.7108\n",
            "Epoch 96/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7339 - accuracy: 0.7042\n",
            "Epoch 97/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7070 - accuracy: 0.7196\n",
            "Epoch 98/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6825 - accuracy: 0.7174\n",
            "Epoch 99/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6582 - accuracy: 0.7329\n",
            "Epoch 100/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6400 - accuracy: 0.7373\n",
            "Epoch 101/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.6177 - accuracy: 0.7439\n",
            "Epoch 102/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6028 - accuracy: 0.7506\n",
            "Epoch 103/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5881 - accuracy: 0.7483\n",
            "Epoch 104/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5770 - accuracy: 0.7528\n",
            "Epoch 105/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5618 - accuracy: 0.7550\n",
            "Epoch 106/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5372 - accuracy: 0.7572\n",
            "Epoch 107/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5151 - accuracy: 0.7616\n",
            "Epoch 108/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4834 - accuracy: 0.7770\n",
            "Epoch 109/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.4936 - accuracy: 0.7704\n",
            "Epoch 110/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4739 - accuracy: 0.7638\n",
            "Epoch 111/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4675 - accuracy: 0.7638\n",
            "Epoch 112/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.4447 - accuracy: 0.7616\n",
            "Epoch 113/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4127 - accuracy: 0.7638\n",
            "Epoch 114/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3808 - accuracy: 0.7837\n",
            "Epoch 115/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3580 - accuracy: 0.7947\n",
            "Epoch 116/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3281 - accuracy: 0.7991\n",
            "Epoch 117/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3072 - accuracy: 0.8057\n",
            "Epoch 118/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2874 - accuracy: 0.8168\n",
            "Epoch 119/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2693 - accuracy: 0.8168\n",
            "Epoch 120/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.2504 - accuracy: 0.8212\n",
            "Epoch 121/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.2379 - accuracy: 0.8322\n",
            "Epoch 122/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2222 - accuracy: 0.8411\n",
            "Epoch 123/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2142 - accuracy: 0.8322\n",
            "Epoch 124/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1922 - accuracy: 0.8433\n",
            "Epoch 125/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1839 - accuracy: 0.8389\n",
            "Epoch 126/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.1671 - accuracy: 0.8499\n",
            "Epoch 127/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1516 - accuracy: 0.8521\n",
            "Epoch 128/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.1364 - accuracy: 0.8499\n",
            "Epoch 129/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1180 - accuracy: 0.8565\n",
            "Epoch 130/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.1002 - accuracy: 0.8609\n",
            "Epoch 131/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.0851 - accuracy: 0.8543\n",
            "Epoch 132/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0699 - accuracy: 0.8675\n",
            "Epoch 133/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0598 - accuracy: 0.8587\n",
            "Epoch 134/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.0457 - accuracy: 0.8609\n",
            "Epoch 135/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0351 - accuracy: 0.8653\n",
            "Epoch 136/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0205 - accuracy: 0.8808\n",
            "Epoch 137/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.0119 - accuracy: 0.8786\n",
            "Epoch 138/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0102 - accuracy: 0.8852\n",
            "Epoch 139/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0709 - accuracy: 0.8653\n",
            "Epoch 140/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.0558 - accuracy: 0.8631\n",
            "Epoch 141/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.0516 - accuracy: 0.8565\n",
            "Epoch 142/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.0451 - accuracy: 0.8609\n",
            "Epoch 143/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0128 - accuracy: 0.8675\n",
            "Epoch 144/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0041 - accuracy: 0.8675\n",
            "Epoch 145/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.9677 - accuracy: 0.8764\n",
            "Epoch 146/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9485 - accuracy: 0.8852\n",
            "Epoch 147/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.9294 - accuracy: 0.8852\n",
            "Epoch 148/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9164 - accuracy: 0.8918\n",
            "Epoch 149/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9023 - accuracy: 0.8940\n",
            "Epoch 150/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8926 - accuracy: 0.8962\n",
            "Epoch 151/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8746 - accuracy: 0.9007\n",
            "Epoch 152/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8528 - accuracy: 0.8985\n",
            "Epoch 153/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.8391 - accuracy: 0.9051\n",
            "Epoch 154/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8266 - accuracy: 0.9029\n",
            "Epoch 155/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8165 - accuracy: 0.9095\n",
            "Epoch 156/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8049 - accuracy: 0.9117\n",
            "Epoch 157/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7920 - accuracy: 0.9117\n",
            "Epoch 158/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7848 - accuracy: 0.9139\n",
            "Epoch 159/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7723 - accuracy: 0.9161\n",
            "Epoch 160/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7750 - accuracy: 0.9205\n",
            "Epoch 161/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7532 - accuracy: 0.9205\n",
            "Epoch 162/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7468 - accuracy: 0.9183\n",
            "Epoch 163/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7358 - accuracy: 0.9183\n",
            "Epoch 164/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7287 - accuracy: 0.9205\n",
            "Epoch 165/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7203 - accuracy: 0.9183\n",
            "Epoch 166/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7146 - accuracy: 0.9205\n",
            "Epoch 167/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7135 - accuracy: 0.9205\n",
            "Epoch 168/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6958 - accuracy: 0.9249\n",
            "Epoch 169/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7067 - accuracy: 0.9161\n",
            "Epoch 170/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6934 - accuracy: 0.9227\n",
            "Epoch 171/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7345 - accuracy: 0.9139\n",
            "Epoch 172/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7015 - accuracy: 0.9183\n",
            "Epoch 173/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6835 - accuracy: 0.9249\n",
            "Epoch 174/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6772 - accuracy: 0.9316\n",
            "Epoch 175/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6546 - accuracy: 0.9272\n",
            "Epoch 176/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6438 - accuracy: 0.9294\n",
            "Epoch 177/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6298 - accuracy: 0.9382\n",
            "Epoch 178/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6198 - accuracy: 0.9360\n",
            "Epoch 179/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6146 - accuracy: 0.9404\n",
            "Epoch 180/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6147 - accuracy: 0.9382\n",
            "Epoch 181/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6033 - accuracy: 0.9426\n",
            "Epoch 182/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5925 - accuracy: 0.9404\n",
            "Epoch 183/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5834 - accuracy: 0.9426\n",
            "Epoch 184/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5752 - accuracy: 0.9448\n",
            "Epoch 185/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5704 - accuracy: 0.9404\n",
            "Epoch 186/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5624 - accuracy: 0.9426\n",
            "Epoch 187/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5560 - accuracy: 0.9448\n",
            "Epoch 188/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5508 - accuracy: 0.9426\n",
            "Epoch 189/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5447 - accuracy: 0.9448\n",
            "Epoch 190/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5395 - accuracy: 0.9448\n",
            "Epoch 191/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5331 - accuracy: 0.9448\n",
            "Epoch 192/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5267 - accuracy: 0.9448\n",
            "Epoch 193/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5200 - accuracy: 0.9448\n",
            "Epoch 194/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5143 - accuracy: 0.9426\n",
            "Epoch 195/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5077 - accuracy: 0.9426\n",
            "Epoch 196/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5023 - accuracy: 0.9448\n",
            "Epoch 197/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4989 - accuracy: 0.9448\n",
            "Epoch 198/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4924 - accuracy: 0.9470\n",
            "Epoch 199/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4875 - accuracy: 0.9470\n",
            "Epoch 200/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4823 - accuracy: 0.9470\n",
            "Epoch 201/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4773 - accuracy: 0.9448\n",
            "Epoch 202/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4717 - accuracy: 0.9426\n",
            "Epoch 203/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4699 - accuracy: 0.9448\n",
            "Epoch 204/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4627 - accuracy: 0.9426\n",
            "Epoch 205/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4585 - accuracy: 0.9426\n",
            "Epoch 206/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4529 - accuracy: 0.9426\n",
            "Epoch 207/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4502 - accuracy: 0.9426\n",
            "Epoch 208/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4437 - accuracy: 0.9470\n",
            "Epoch 209/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4400 - accuracy: 0.9470\n",
            "Epoch 210/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4367 - accuracy: 0.9448\n",
            "Epoch 211/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4376 - accuracy: 0.9404\n",
            "Epoch 212/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4308 - accuracy: 0.9426\n",
            "Epoch 213/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4258 - accuracy: 0.9426\n",
            "Epoch 214/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4206 - accuracy: 0.9448\n",
            "Epoch 215/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.9470\n",
            "Epoch 216/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4148 - accuracy: 0.9448\n",
            "Epoch 217/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.9448\n",
            "Epoch 218/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4042 - accuracy: 0.9448\n",
            "Epoch 219/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.9448\n",
            "Epoch 220/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4046 - accuracy: 0.9470\n",
            "Epoch 221/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4667 - accuracy: 0.9272\n",
            "Epoch 222/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4714 - accuracy: 0.9360\n",
            "Epoch 223/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4504 - accuracy: 0.9316\n",
            "Epoch 224/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4445 - accuracy: 0.9338\n",
            "Epoch 225/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 0.9382\n",
            "Epoch 226/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.9404\n",
            "Epoch 227/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4077 - accuracy: 0.9360\n",
            "Epoch 228/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.9448\n",
            "Epoch 229/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.9426\n",
            "Epoch 230/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3718 - accuracy: 0.9448\n",
            "Epoch 231/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3726 - accuracy: 0.9448\n",
            "Epoch 232/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3641 - accuracy: 0.9470\n",
            "Epoch 233/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3585 - accuracy: 0.9470\n",
            "Epoch 234/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3546 - accuracy: 0.9470\n",
            "Epoch 235/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3514 - accuracy: 0.9448\n",
            "Epoch 236/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3470 - accuracy: 0.9448\n",
            "Epoch 237/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3437 - accuracy: 0.9448\n",
            "Epoch 238/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3408 - accuracy: 0.9426\n",
            "Epoch 239/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3396 - accuracy: 0.9426\n",
            "Epoch 240/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3339 - accuracy: 0.9448\n",
            "Epoch 241/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3309 - accuracy: 0.9470\n",
            "Epoch 242/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3283 - accuracy: 0.9448\n",
            "Epoch 243/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3250 - accuracy: 0.9470\n",
            "Epoch 244/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3219 - accuracy: 0.9470\n",
            "Epoch 245/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3194 - accuracy: 0.9492\n",
            "Epoch 246/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3160 - accuracy: 0.9492\n",
            "Epoch 247/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3139 - accuracy: 0.9470\n",
            "Epoch 248/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3127 - accuracy: 0.9492\n",
            "Epoch 249/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3091 - accuracy: 0.9492\n",
            "Epoch 250/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3058 - accuracy: 0.9470\n",
            "Epoch 251/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3048 - accuracy: 0.9492\n",
            "Epoch 252/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3017 - accuracy: 0.9470\n",
            "Epoch 253/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2985 - accuracy: 0.9448\n",
            "Epoch 254/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3003 - accuracy: 0.9514\n",
            "Epoch 255/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2965 - accuracy: 0.9492\n",
            "Epoch 256/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2947 - accuracy: 0.9470\n",
            "Epoch 257/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2897 - accuracy: 0.9470\n",
            "Epoch 258/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2878 - accuracy: 0.9492\n",
            "Epoch 259/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2859 - accuracy: 0.9492\n",
            "Epoch 260/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2830 - accuracy: 0.9470\n",
            "Epoch 261/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2808 - accuracy: 0.9492\n",
            "Epoch 262/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2796 - accuracy: 0.9492\n",
            "Epoch 263/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2777 - accuracy: 0.9514\n",
            "Epoch 264/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2755 - accuracy: 0.9470\n",
            "Epoch 265/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2726 - accuracy: 0.9492\n",
            "Epoch 266/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2700 - accuracy: 0.9514\n",
            "Epoch 267/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2670 - accuracy: 0.9514\n",
            "Epoch 268/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2658 - accuracy: 0.9470\n",
            "Epoch 269/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2645 - accuracy: 0.9470\n",
            "Epoch 270/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2620 - accuracy: 0.9514\n",
            "Epoch 271/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2597 - accuracy: 0.9492\n",
            "Epoch 272/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2585 - accuracy: 0.9470\n",
            "Epoch 273/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2563 - accuracy: 0.9492\n",
            "Epoch 274/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2557 - accuracy: 0.9470\n",
            "Epoch 275/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2539 - accuracy: 0.9492\n",
            "Epoch 276/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2524 - accuracy: 0.9514\n",
            "Epoch 277/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2512 - accuracy: 0.9514\n",
            "Epoch 278/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2490 - accuracy: 0.9448\n",
            "Epoch 279/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2485 - accuracy: 0.9492\n",
            "Epoch 280/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2480 - accuracy: 0.9470\n",
            "Epoch 281/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2438 - accuracy: 0.9492\n",
            "Epoch 282/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2419 - accuracy: 0.9470\n",
            "Epoch 283/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2420 - accuracy: 0.9492\n",
            "Epoch 284/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2398 - accuracy: 0.9536\n",
            "Epoch 285/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2361 - accuracy: 0.9470\n",
            "Epoch 286/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2348 - accuracy: 0.9492\n",
            "Epoch 287/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2329 - accuracy: 0.9492\n",
            "Epoch 288/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2331 - accuracy: 0.9470\n",
            "Epoch 289/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2325 - accuracy: 0.9470\n",
            "Epoch 290/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2287 - accuracy: 0.9492\n",
            "Epoch 291/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2274 - accuracy: 0.9448\n",
            "Epoch 292/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2263 - accuracy: 0.9470\n",
            "Epoch 293/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2248 - accuracy: 0.9492\n",
            "Epoch 294/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2220 - accuracy: 0.9514\n",
            "Epoch 295/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2208 - accuracy: 0.9492\n",
            "Epoch 296/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2204 - accuracy: 0.9492\n",
            "Epoch 297/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2202 - accuracy: 0.9470\n",
            "Epoch 298/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2174 - accuracy: 0.9492\n",
            "Epoch 299/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2163 - accuracy: 0.9470\n",
            "Epoch 300/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2144 - accuracy: 0.9514\n",
            "Epoch 301/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2127 - accuracy: 0.9514\n",
            "Epoch 302/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2122 - accuracy: 0.9514\n",
            "Epoch 303/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2107 - accuracy: 0.9470\n",
            "Epoch 304/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2090 - accuracy: 0.9492\n",
            "Epoch 305/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2076 - accuracy: 0.9492\n",
            "Epoch 306/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2069 - accuracy: 0.9470\n",
            "Epoch 307/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2059 - accuracy: 0.9558\n",
            "Epoch 308/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2050 - accuracy: 0.9470\n",
            "Epoch 309/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2036 - accuracy: 0.9514\n",
            "Epoch 310/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2022 - accuracy: 0.9470\n",
            "Epoch 311/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2017 - accuracy: 0.9514\n",
            "Epoch 312/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2005 - accuracy: 0.9514\n",
            "Epoch 313/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1993 - accuracy: 0.9492\n",
            "Epoch 314/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1986 - accuracy: 0.9514\n",
            "Epoch 315/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1969 - accuracy: 0.9514\n",
            "Epoch 316/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1963 - accuracy: 0.9470\n",
            "Epoch 317/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1997 - accuracy: 0.9470\n",
            "Epoch 318/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1951 - accuracy: 0.9470\n",
            "Epoch 319/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1933 - accuracy: 0.9470\n",
            "Epoch 320/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1942 - accuracy: 0.9514\n",
            "Epoch 321/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1926 - accuracy: 0.9514\n",
            "Epoch 322/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2511 - accuracy: 0.9448\n",
            "Epoch 323/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2579 - accuracy: 0.9360\n",
            "Epoch 324/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2547 - accuracy: 0.9382\n",
            "Epoch 325/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2323 - accuracy: 0.9426\n",
            "Epoch 326/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2255 - accuracy: 0.9404\n",
            "Epoch 327/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2181 - accuracy: 0.9448\n",
            "Epoch 328/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2557 - accuracy: 0.9426\n",
            "Epoch 329/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2353 - accuracy: 0.9514\n",
            "Epoch 330/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2178 - accuracy: 0.9514\n",
            "Epoch 331/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2550 - accuracy: 0.9360\n",
            "Epoch 332/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2388 - accuracy: 0.9360\n",
            "Epoch 333/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2245 - accuracy: 0.9448\n",
            "Epoch 334/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2288 - accuracy: 0.9404\n",
            "Epoch 335/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2083 - accuracy: 0.9514\n",
            "Epoch 336/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2038 - accuracy: 0.9426\n",
            "Epoch 337/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1967 - accuracy: 0.9426\n",
            "Epoch 338/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1923 - accuracy: 0.9492\n",
            "Epoch 339/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1917 - accuracy: 0.9426\n",
            "Epoch 340/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1845 - accuracy: 0.9514\n",
            "Epoch 341/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1828 - accuracy: 0.9514\n",
            "Epoch 342/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1803 - accuracy: 0.9492\n",
            "Epoch 343/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1792 - accuracy: 0.9492\n",
            "Epoch 344/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1770 - accuracy: 0.9492\n",
            "Epoch 345/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1759 - accuracy: 0.9448\n",
            "Epoch 346/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1745 - accuracy: 0.9514\n",
            "Epoch 347/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1725 - accuracy: 0.9492\n",
            "Epoch 348/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1721 - accuracy: 0.9470\n",
            "Epoch 349/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1707 - accuracy: 0.9470\n",
            "Epoch 350/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1691 - accuracy: 0.9492\n",
            "Epoch 351/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1677 - accuracy: 0.9470\n",
            "Epoch 352/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1665 - accuracy: 0.9492\n",
            "Epoch 353/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1648 - accuracy: 0.9536\n",
            "Epoch 354/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1642 - accuracy: 0.9514\n",
            "Epoch 355/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1639 - accuracy: 0.9492\n",
            "Epoch 356/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1650 - accuracy: 0.9492\n",
            "Epoch 357/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1645 - accuracy: 0.9514\n",
            "Epoch 358/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1629 - accuracy: 0.9492\n",
            "Epoch 359/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1611 - accuracy: 0.9470\n",
            "Epoch 360/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1598 - accuracy: 0.9470\n",
            "Epoch 361/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1584 - accuracy: 0.9470\n",
            "Epoch 362/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1582 - accuracy: 0.9470\n",
            "Epoch 363/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1582 - accuracy: 0.9426\n",
            "Epoch 364/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1570 - accuracy: 0.9514\n",
            "Epoch 365/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1563 - accuracy: 0.9470\n",
            "Epoch 366/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1565 - accuracy: 0.9448\n",
            "Epoch 367/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1556 - accuracy: 0.9492\n",
            "Epoch 368/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1543 - accuracy: 0.9470\n",
            "Epoch 369/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1537 - accuracy: 0.9514\n",
            "Epoch 370/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1539 - accuracy: 0.9470\n",
            "Epoch 371/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1527 - accuracy: 0.9514\n",
            "Epoch 372/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1529 - accuracy: 0.9448\n",
            "Epoch 373/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1524 - accuracy: 0.9492\n",
            "Epoch 374/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1518 - accuracy: 0.9514\n",
            "Epoch 375/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1506 - accuracy: 0.9470\n",
            "Epoch 376/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1501 - accuracy: 0.9470\n",
            "Epoch 377/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1499 - accuracy: 0.9470\n",
            "Epoch 378/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1491 - accuracy: 0.9492\n",
            "Epoch 379/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1489 - accuracy: 0.9470\n",
            "Epoch 380/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1478 - accuracy: 0.9514\n",
            "Epoch 381/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1493 - accuracy: 0.9470\n",
            "Epoch 382/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1499 - accuracy: 0.9470\n",
            "Epoch 383/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1482 - accuracy: 0.9448\n",
            "Epoch 384/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1454 - accuracy: 0.9514\n",
            "Epoch 385/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1459 - accuracy: 0.9470\n",
            "Epoch 386/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1456 - accuracy: 0.9492\n",
            "Epoch 387/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1460 - accuracy: 0.9514\n",
            "Epoch 388/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1461 - accuracy: 0.9536\n",
            "Epoch 389/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1454 - accuracy: 0.9514\n",
            "Epoch 390/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1436 - accuracy: 0.9492\n",
            "Epoch 391/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1432 - accuracy: 0.9470\n",
            "Epoch 392/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1427 - accuracy: 0.9514\n",
            "Epoch 393/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1415 - accuracy: 0.9492\n",
            "Epoch 394/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1406 - accuracy: 0.9514\n",
            "Epoch 395/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1405 - accuracy: 0.9470\n",
            "Epoch 396/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1397 - accuracy: 0.9492\n",
            "Epoch 397/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1398 - accuracy: 0.9492\n",
            "Epoch 398/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1393 - accuracy: 0.9448\n",
            "Epoch 399/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1395 - accuracy: 0.9514\n",
            "Epoch 400/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1390 - accuracy: 0.9448\n",
            "Epoch 401/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1381 - accuracy: 0.9404\n",
            "Epoch 402/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1376 - accuracy: 0.9514\n",
            "Epoch 403/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1400 - accuracy: 0.9492\n",
            "Epoch 404/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1388 - accuracy: 0.9448\n",
            "Epoch 405/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1368 - accuracy: 0.9492\n",
            "Epoch 406/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1400 - accuracy: 0.9448\n",
            "Epoch 407/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1408 - accuracy: 0.9536\n",
            "Epoch 408/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1378 - accuracy: 0.9448\n",
            "Epoch 409/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1361 - accuracy: 0.9470\n",
            "Epoch 410/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1352 - accuracy: 0.9514\n",
            "Epoch 411/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1348 - accuracy: 0.9426\n",
            "Epoch 412/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1347 - accuracy: 0.9514\n",
            "Epoch 413/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1329 - accuracy: 0.9514\n",
            "Epoch 414/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1342 - accuracy: 0.9492\n",
            "Epoch 415/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1338 - accuracy: 0.9426\n",
            "Epoch 416/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1339 - accuracy: 0.9448\n",
            "Epoch 417/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1326 - accuracy: 0.9404\n",
            "Epoch 418/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1319 - accuracy: 0.9470\n",
            "Epoch 419/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1331 - accuracy: 0.9514\n",
            "Epoch 420/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1331 - accuracy: 0.9448\n",
            "Epoch 421/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1299 - accuracy: 0.9470\n",
            "Epoch 422/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1315 - accuracy: 0.9448\n",
            "Epoch 423/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1309 - accuracy: 0.9514\n",
            "Epoch 424/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1299 - accuracy: 0.9470\n",
            "Epoch 425/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1292 - accuracy: 0.9514\n",
            "Epoch 426/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1284 - accuracy: 0.9492\n",
            "Epoch 427/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1287 - accuracy: 0.9448\n",
            "Epoch 428/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1279 - accuracy: 0.9470\n",
            "Epoch 429/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1279 - accuracy: 0.9492\n",
            "Epoch 430/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1278 - accuracy: 0.9492\n",
            "Epoch 431/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1282 - accuracy: 0.9470\n",
            "Epoch 432/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1273 - accuracy: 0.9448\n",
            "Epoch 433/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1268 - accuracy: 0.9514\n",
            "Epoch 434/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1264 - accuracy: 0.9492\n",
            "Epoch 435/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1286 - accuracy: 0.9492\n",
            "Epoch 436/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1279 - accuracy: 0.9514\n",
            "Epoch 437/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1267 - accuracy: 0.9470\n",
            "Epoch 438/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1253 - accuracy: 0.9470\n",
            "Epoch 439/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1251 - accuracy: 0.9426\n",
            "Epoch 440/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1243 - accuracy: 0.9492\n",
            "Epoch 441/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1251 - accuracy: 0.9514\n",
            "Epoch 442/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1284 - accuracy: 0.9448\n",
            "Epoch 443/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1264 - accuracy: 0.9492\n",
            "Epoch 444/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1257 - accuracy: 0.9514\n",
            "Epoch 445/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1245 - accuracy: 0.9514\n",
            "Epoch 446/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1246 - accuracy: 0.9470\n",
            "Epoch 447/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1237 - accuracy: 0.9492\n",
            "Epoch 448/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1233 - accuracy: 0.9492\n",
            "Epoch 449/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1221 - accuracy: 0.9470\n",
            "Epoch 450/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1307 - accuracy: 0.9514\n",
            "Epoch 451/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1443 - accuracy: 0.9492\n",
            "Epoch 452/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1510 - accuracy: 0.9470\n",
            "Epoch 453/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1441 - accuracy: 0.9470\n",
            "Epoch 454/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1434 - accuracy: 0.9470\n",
            "Epoch 455/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1376 - accuracy: 0.9470\n",
            "Epoch 456/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1377 - accuracy: 0.9470\n",
            "Epoch 457/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1586 - accuracy: 0.9426\n",
            "Epoch 458/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1552 - accuracy: 0.9448\n",
            "Epoch 459/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1957 - accuracy: 0.9360\n",
            "Epoch 460/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2191 - accuracy: 0.9316\n",
            "Epoch 461/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2091 - accuracy: 0.9338\n",
            "Epoch 462/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2076 - accuracy: 0.9426\n",
            "Epoch 463/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1936 - accuracy: 0.9360\n",
            "Epoch 464/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1763 - accuracy: 0.9404\n",
            "Epoch 465/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1822 - accuracy: 0.9360\n",
            "Epoch 466/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1795 - accuracy: 0.9382\n",
            "Epoch 467/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1549 - accuracy: 0.9426\n",
            "Epoch 468/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1445 - accuracy: 0.9470\n",
            "Epoch 469/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1404 - accuracy: 0.9470\n",
            "Epoch 470/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1358 - accuracy: 0.9470\n",
            "Epoch 471/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1336 - accuracy: 0.9470\n",
            "Epoch 472/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1318 - accuracy: 0.9514\n",
            "Epoch 473/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1300 - accuracy: 0.9514\n",
            "Epoch 474/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1287 - accuracy: 0.9514\n",
            "Epoch 475/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1280 - accuracy: 0.9470\n",
            "Epoch 476/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1270 - accuracy: 0.9536\n",
            "Epoch 477/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1265 - accuracy: 0.9470\n",
            "Epoch 478/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1254 - accuracy: 0.9470\n",
            "Epoch 479/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1244 - accuracy: 0.9514\n",
            "Epoch 480/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1241 - accuracy: 0.9448\n",
            "Epoch 481/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1230 - accuracy: 0.9470\n",
            "Epoch 482/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1227 - accuracy: 0.9492\n",
            "Epoch 483/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1222 - accuracy: 0.9470\n",
            "Epoch 484/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1217 - accuracy: 0.9470\n",
            "Epoch 485/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1195 - accuracy: 0.9492\n",
            "Epoch 486/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1205 - accuracy: 0.9470\n",
            "Epoch 487/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1198 - accuracy: 0.9448\n",
            "Epoch 488/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1186 - accuracy: 0.9536\n",
            "Epoch 489/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1181 - accuracy: 0.9492\n",
            "Epoch 490/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1181 - accuracy: 0.9514\n",
            "Epoch 491/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1171 - accuracy: 0.9514\n",
            "Epoch 492/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1174 - accuracy: 0.9514\n",
            "Epoch 493/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1185 - accuracy: 0.9492\n",
            "Epoch 494/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1168 - accuracy: 0.9470\n",
            "Epoch 495/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1165 - accuracy: 0.9492\n",
            "Epoch 496/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1182 - accuracy: 0.9514\n",
            "Epoch 497/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1171 - accuracy: 0.9514\n",
            "Epoch 498/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1157 - accuracy: 0.9514\n",
            "Epoch 499/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.1156 - accuracy: 0.9514\n",
            "Epoch 500/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.1151 - accuracy: 0.9470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHYQmqPO5cps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vC2OVcp5gb5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "f4a91aac-2cab-4484-ff52-2d54e86d43c9"
      },
      "source": [
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9O-z9MM5kBj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "a9572a7a-1b4b-4585-b89e-2b06a498b165"
      },
      "source": [
        "seed_text = \"Laurence went to dublin\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])\n",
        "\ttoken_list = pad_sequences(token_list, maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Laurence went to dublin new of athy one jeremy lanigan lanigan mchugh mchugh mchugh suppose suppose suppose suppose think of give her a call and reel and a jig jig academy academy academy academy academy academy big peggy entangled a your eyes her together lanigans her her as glisten plenty as a rose rose rose cask cask a as rose and jig eyes and cakes again phelim mchugh a rose mchugh eyes entangled me a rose eyes and cakes again phelim mchugh mchugh from a mchugh hoops by a call call man again again again again dublin suppose mccarthy mccarthy mccarthy mccarthy mccarthy mccarthy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMjMdb93OB8R",
        "colab_type": "text"
      },
      "source": [
        "Predict irish poem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Laa9N3ikJ_wH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "cf284f1d-922b-4b96-a32e-78a3937b6f4c"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/irish-lyrics-eof.txt \\\n",
        "    -O /tmp/irish-lyrics-eof.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-09 22:33:35--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/irish-lyrics-eof.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.13.128, 74.125.133.128, 74.125.140.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.13.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68970 (67K) [text/plain]\n",
            "Saving to: ‘/tmp/irish-lyrics-eof.txt’\n",
            "\n",
            "\r          /tmp/iris   0%[                    ]       0  --.-KB/s               \r/tmp/irish-lyrics-e 100%[===================>]  67.35K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-07-09 22:33:35 (68.6 MB/s) - ‘/tmp/irish-lyrics-eof.txt’ saved [68970/68970]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acm14iuNJ_9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4f44718e-ff2b-4a75-dc9c-03a91622b3c3"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "data = open('/tmp/irish-lyrics-eof.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 1, 'and': 2, 'i': 3, 'to': 4, 'a': 5, 'of': 6, 'my': 7, 'in': 8, 'me': 9, 'for': 10, 'you': 11, 'all': 12, 'was': 13, 'she': 14, 'that': 15, 'on': 16, 'with': 17, 'her': 18, 'but': 19, 'as': 20, 'when': 21, 'love': 22, 'is': 23, 'your': 24, 'it': 25, 'will': 26, 'from': 27, 'by': 28, 'they': 29, 'be': 30, 'are': 31, 'so': 32, 'he': 33, 'old': 34, 'no': 35, 'oh': 36, 'ill': 37, 'at': 38, 'one': 39, 'his': 40, 'there': 41, 'were': 42, 'heart': 43, 'down': 44, 'now': 45, 'we': 46, 'where': 47, 'young': 48, 'never': 49, 'go': 50, 'come': 51, 'then': 52, 'did': 53, 'not': 54, 'said': 55, 'away': 56, 'their': 57, 'sweet': 58, 'them': 59, 'green': 60, 'if': 61, 'take': 62, 'our': 63, 'like': 64, 'night': 65, 'day': 66, 'o': 67, 'out': 68, 'fair': 69, 'this': 70, 'town': 71, 'have': 72, 'can': 73, 'true': 74, 'its': 75, 'thou': 76, 'see': 77, 'dear': 78, 'more': 79, 'theres': 80, 'or': 81, 'had': 82, 'would': 83, 'over': 84, 'hear': 85, 'up': 86, 'ive': 87, 'through': 88, 'home': 89, 'again': 90, 'well': 91, 'oer': 92, 'land': 93, 'good': 94, 'im': 95, 'ye': 96, 'sea': 97, 'left': 98, 'still': 99, 'father': 100, 'long': 101, 'rose': 102, 'could': 103, 'morning': 104, 'wild': 105, 'who': 106, 'eyes': 107, 'came': 108, 'while': 109, 'too': 110, 'back': 111, 'little': 112, 'an': 113, 'took': 114, 'him': 115, 'bow': 116, 'first': 117, 'let': 118, 'man': 119, 'shall': 120, 'know': 121, 'get': 122, 'high': 123, 'gone': 124, 'say': 125, 'ever': 126, 'some': 127, 'mary': 128, 'hand': 129, 'till': 130, 'put': 131, 'own': 132, 'time': 133, 'heard': 134, 'dead': 135, 'may': 136, 'bright': 137, 'mountain': 138, 'early': 139, 'rosin': 140, 'gave': 141, 'thee': 142, 'only': 143, 'far': 144, 'maid': 145, 'must': 146, 'find': 147, 'girl': 148, 'sure': 149, 'round': 150, 'dublin': 151, 'once': 152, 'world': 153, 'delight': 154, 'last': 155, 'johnny': 156, 'seen': 157, 'has': 158, 'fine': 159, 'road': 160, 'mother': 161, 'tis': 162, 'what': 163, 'way': 164, 'moon': 165, 'soul': 166, 'neer': 167, 'id': 168, 'just': 169, 'thats': 170, 'days': 171, 'darling': 172, 'went': 173, 'white': 174, 'die': 175, 'than': 176, 'hair': 177, 'goes': 178, 'meet': 179, 'today': 180, 'do': 181, 'girls': 182, 'shes': 183, 'thyme': 184, 'thy': 185, 'sing': 186, 'pretty': 187, 'new': 188, 'poor': 189, 'into': 190, 'life': 191, 'irish': 192, 'give': 193, 'boy': 194, 'youre': 195, 'make': 196, 'passed': 197, 'lovely': 198, 'black': 199, 'youll': 200, 'died': 201, 'red': 202, 'smile': 203, 'keep': 204, 'loves': 205, 'free': 206, 'leave': 207, 'friends': 208, 'each': 209, 'saw': 210, 'behind': 211, 'song': 212, 'ra': 213, 'dont': 214, 'arms': 215, 'am': 216, 'sun': 217, 'saying': 218, 'made': 219, 'wish': 220, 'cold': 221, 'met': 222, 'before': 223, 'should': 224, 'rocky': 225, 'light': 226, 'wid': 227, 'boys': 228, 'best': 229, 'fields': 230, 'since': 231, 'ball': 232, 'water': 233, 'casey': 234, 'mind': 235, 'along': 236, 'loved': 237, 'place': 238, 'ireland': 239, 'next': 240, 'three': 241, 'many': 242, 'years': 243, 'door': 244, 'us': 245, 'drink': 246, 'got': 247, 'might': 248, 'live': 249, 'roses': 250, 'play': 251, 'soon': 252, 'ground': 253, 'times': 254, 'spent': 255, 'going': 256, 'tree': 257, 'barley': 258, 'grass': 259, 'kind': 260, 'twas': 261, 'bridge': 262, 'around': 263, 'blue': 264, 'tell': 265, 'row': 266, 'how': 267, 'money': 268, 'merry': 269, 'stepped': 270, 'corporal': 271, 'always': 272, 'though': 273, 'near': 274, 'taken': 275, 'ones': 276, 'daughter': 277, 'forever': 278, 'loo': 279, 'shining': 280, 'plenty': 281, 'hes': 282, 'ship': 283, 'banks': 284, 'think': 285, 'very': 286, 'stand': 287, 'heres': 288, 'snow': 289, 'mountains': 290, 'molly': 291, 'wheel': 292, 'street': 293, 'erin': 294, 'side': 295, 'feet': 296, 'star': 297, 'look': 298, 'brave': 299, 'woman': 300, 'sons': 301, 'two': 302, 'says': 303, 'asked': 304, 'lanigans': 305, 'singing': 306, 'men': 307, 'toome': 308, 'stole': 309, 'god': 310, 'hill': 311, 'lonely': 312, 'lover': 313, 'tears': 314, 'fathers': 315, 'low': 316, 'voice': 317, 'quite': 318, 'able': 319, 'nice': 320, 'laid': 321, 'comrades': 322, 'wind': 323, 'another': 324, 'sit': 325, 'face': 326, 'band': 327, 'call': 328, 'colleen': 329, 'until': 330, 'hills': 331, 'mine': 332, 'above': 333, 'upon': 334, 'eer': 335, 'youve': 336, 'fly': 337, 'been': 338, 'late': 339, 'alive': 340, 'ballyjamesduff': 341, 'looked': 342, 'great': 343, 'why': 344, 'every': 345, 'proud': 346, 'found': 347, 'bragh': 348, 'such': 349, 'birds': 350, 'wedding': 351, 'welcome': 352, 'dancing': 353, 'da': 354, 'fell': 355, 'thinking': 356, 'roddy': 357, 'mccorley': 358, 'smiling': 359, 'mallow': 360, 'blooming': 361, 'thought': 362, 'peace': 363, 'soft': 364, 'pure': 365, 'harp': 366, 'dream': 367, 'alas': 368, 'yet': 369, 'clear': 370, 'art': 371, 'off': 372, 'hope': 373, 'fought': 374, 'mothers': 375, 'shore': 376, 'ago': 377, 'fol': 378, 'de': 379, 'house': 380, 'married': 381, 'bound': 382, 'danced': 383, 'devil': 384, 'dawning': 385, 'makes': 386, 'same': 387, 'sat': 388, 'any': 389, 'glass': 390, 'gay': 391, 'relations': 392, 'evening': 393, 'watched': 394, 'right': 395, 'fellows': 396, 'whiskey': 397, 'bonnie': 398, 'grows': 399, 'women': 400, 'flowers': 401, 'beauty': 402, 'cannot': 403, 'handsome': 404, 'happy': 405, 'gold': 406, 'rover': 407, 'none': 408, 'doneen': 409, 'summers': 410, 'people': 411, 'set': 412, 'paddy': 413, 'morn': 414, 'most': 415, 'easy': 416, 'struck': 417, 'beautiful': 418, 'those': 419, 'golden': 420, 'run': 421, 'pipes': 422, 'glen': 423, 'dying': 424, 'here': 425, 'wall': 426, 'across': 427, 'fire': 428, 'eileen': 429, 'longer': 430, 'cheeks': 431, 'valley': 432, 'both': 433, 'dew': 434, 'care': 435, 'bride': 436, 'nothing': 437, 'wont': 438, 'theyre': 439, 'colonel': 440, 'maiden': 441, 'shed': 442, 'til': 443, 'brown': 444, 'breast': 445, 'corn': 446, 'sinking': 447, 'began': 448, 'name': 449, 'cruel': 450, 'sound': 451, 'spancil': 452, 'county': 453, 'lies': 454, 'color': 455, 'thing': 456, 'decay': 457, 'sleep': 458, 'hours': 459, 'loving': 460, 'weary': 461, 'ringing': 462, 'please': 463, 'forget': 464, 'lie': 465, 'ran': 466, 'tore': 467, 'country': 468, 'fear': 469, 'fortune': 470, 'kissed': 471, 'alone': 472, 'ould': 473, 'cry': 474, 'dreams': 475, 'used': 476, 'horse': 477, 'break': 478, 'bells': 479, 'didnt': 480, 'weeks': 481, 'without': 482, 'raw': 483, 'nor': 484, 'twenty': 485, 'tune': 486, 'hed': 487, 'roving': 488, 'leaves': 489, 'cant': 490, 'death': 491, 'ten': 492, 'prison': 493, 'judge': 494, 'against': 495, 'lads': 496, 'shell': 497, 'fill': 498, 'valleys': 499, 'other': 500, 'pale': 501, 'joy': 502, 'wide': 503, 'bring': 504, 'ah': 505, 'cliffs': 506, 'city': 507, 'end': 508, 'turn': 509, 'sky': 510, 'born': 511, 'knew': 512, 'smiled': 513, 'rosie': 514, 'comes': 515, 'sayin': 516, 'lord': 517, 'dungannon': 518, 'blood': 519, 'air': 520, 'danny': 521, 'calling': 522, 'sunshine': 523, 'spring': 524, 'bid': 525, 'grow': 526, 'truth': 527, 'tear': 528, 'rings': 529, 'guns': 530, 'bay': 531, 'oflynn': 532, 'och': 533, 'stick': 534, 'rest': 535, 'four': 536, 'jewel': 537, 'tried': 538, 'grief': 539, 'answer': 540, 'kathleen': 541, 'fond': 542, 'eye': 543, 'goin': 544, 'pistols': 545, 'musha': 546, 'whack': 547, 'creole': 548, 'together': 549, 'room': 550, 'fall': 551, 'swore': 552, 'being': 553, 'step': 554, 'lark': 555, 'cailín': 556, 'deas': 557, 'crúite': 558, 'na': 559, 'mbó': 560, 'sir': 561, 'isle': 562, 'waiting': 563, 'magic': 564, 'skibbereen': 565, 'loud': 566, 'raise': 567, 'bent': 568, 'aged': 569, 'summer': 570, 'jenny': 571, 'excise': 572, 'rigadoo': 573, 'auld': 574, 'hearts': 575, 'nay': 576, 'stool': 577, 'farrell': 578, 'garden': 579, 'precious': 580, 'child': 581, 'slumber': 582, 'sleeping': 583, 'watch': 584, 'gently': 585, 'minstrel': 586, 'praise': 587, 'bell': 588, 'shaken': 589, 'immortal': 590, 'pray': 591, 'stay': 592, 'spoke': 593, 'cross': 594, 'brothers': 595, 'much': 596, 'past': 597, 'killarney': 598, 'sang': 599, 'tones': 600, 'ral': 601, 'wander': 602, 'cot': 603, 'feel': 604, 'yore': 605, 'answered': 606, 'divil': 607, 'middle': 608, 'bit': 609, 'led': 610, 'soldiers': 611, 'lily': 612, 'bed': 613, 'lassie': 614, 'clothes': 615, 'return': 616, 'broken': 617, 'derry': 618, 'sighed': 619, 'english': 620, 'tomorrow': 621, 'souls': 622, 'van': 623, 'diemans': 624, 'law': 625, 'neither': 626, 'winds': 627, 'rather': 628, 'doesnt': 629, 'rosy': 630, 'neatest': 631, 'hands': 632, 'whereon': 633, 'stands': 634, 'write': 635, 'thousand': 636, 'fare': 637, 'youd': 638, 'velvet': 639, 'neat': 640, 'landed': 641, 'health': 642, 'kellswater': 643, 'quiet': 644, 'stars': 645, 'beside': 646, 'warm': 647, 'sunday': 648, 'grey': 649, 'ocean': 650, 'sad': 651, 'spend': 652, 'kilkenny': 653, 'silver': 654, 'view': 655, 'west': 656, 'plain': 657, 'barrow': 658, 'broad': 659, 'narrow': 660, 'crying': 661, 'wonder': 662, 'save': 663, 'stop': 664, 'tender': 665, 'told': 666, 'lip': 667, 'dance': 668, 'foot': 669, 'kilrain': 670, 'saint': 671, 'visit': 672, 'mossy': 673, 'wexford': 674, 'irishmen': 675, 'shadow': 676, 'tho': 677, 'salley': 678, 'gardens': 679, 'foolish': 680, 'youth': 681, 'fade': 682, 'war': 683, 'believe': 684, 'which': 685, 'change': 686, 'entwine': 687, 'turns': 688, 'turned': 689, 'crown': 690, 'played': 691, 'captain': 692, 'blow': 693, 'children': 694, 'slainte': 695, 'gentle': 696, 'heavens': 697, 'bloom': 698, 'grand': 699, 'bush': 700, 'nest': 701, 'rich': 702, 'parting': 703, 'better': 704, 'window': 705, 'haste': 706, 'fresh': 707, 'stream': 708, 'rays': 709, 'ma': 710, 'ring': 711, 'lad': 712, 'athy': 713, 'drop': 714, 'hardly': 715, 'done': 716, 'arm': 717, 'leg': 718, 'beg': 719, 'drew': 720, 'bold': 721, 'drawn': 722, 'jail': 723, 'writin': 724, 'farewell': 725, 'tired': 726, 'lake': 727, 'want': 728, 'ringlets': 729, 'myself': 730, 'songs': 731, 'reel': 732, 'steps': 733, 'hearty': 734, 'fainted': 735, 'called': 736, 'under': 737, 'toe': 738, 'mairi': 739, 'fairest': 740, 'darlin': 741, 'bird': 742, 'memory': 743, 'lips': 744, 'sweetly': 745, 'morrow': 746, 'consent': 747, 'else': 748, 'sold': 749, 'stout': 750, 'pair': 751, 'drinking': 752, 'meself': 753, 'fray': 754, 'pike': 755, 'coat': 756, 'beneath': 757, 'rent': 758, 'part': 759, 'half': 760, 'head': 761, 'friend': 762, 'standing': 763, 'floor': 764, 'bare': 765, 'wed': 766, 'son': 767, 'pride': 768, 'vision': 769, 'sword': 770, 'after': 771, 'won': 772, 'farmers': 773, 'flower': 774, 'nut': 775, 'surely': 776, 'stood': 777, 'wandered': 778, 'athenry': 779, 'rising': 780, 'beating': 781, 'form': 782, 'dhu': 783, 'buy': 784, 'laughter': 785, 'wear': 786, 'raking': 787, 'rakes': 788, 'claret': 789, 'shure': 790, 'tralee': 791, 'slower': 792, 'lower': 793, 'deep': 794, 'wearin': 795, 'duram': 796, 'takes': 797, 'beware': 798, 'steal': 799, 'brings': 800, 'things': 801, 'joys': 802, 'bunch': 803, 'sailor': 804, 'chanced': 805, 'pass': 806, 'angels': 807, 'send': 808, 'drowsy': 809, 'keeping': 810, 'spirit': 811, 'stealing': 812, 'feeling': 813, 'roam': 814, 'presence': 815, 'heavenward': 816, 'dust': 817, 'dim': 818, 'journey': 819, 'waves': 820, 'frightened': 821, 'leaving': 822, 'struggle': 823, 'parents': 824, 'courage': 825, 'weeping': 826, 'pain': 827, 'mist': 828, 'felt': 829, 'roared': 830, 'making': 831, 'fever': 832, 'moment': 833, 'distance': 834, 'wailing': 835, 'oft': 836, 'held': 837, 'fast': 838, 'cabin': 839, 'honey': 840, 'diddle': 841, 'clearly': 842, 'open': 843, 'opened': 844, 'table': 845, 'wine': 846, 'lay': 847, 'shells': 848, 'sailed': 849, 'drown': 850, 'fetters': 851, 'chains': 852, 'wives': 853, 'sorrow': 854, 'thoughts': 855, 'cursed': 856, 'hell': 857, 'five': 858, 'buried': 859, 'lost': 860, 'endless': 861, 'slavery': 862, 'gun': 863, 'rain': 864, 'cares': 865, 'ghosts': 866, 'runaway': 867, 'twill': 868, 'month': 869, 'meadows': 870, 'prettiest': 871, 'winters': 872, 'satisfied': 873, 'few': 874, 'short': 875, 'lines': 876, 'shone': 877, 'shoulder': 878, 'belfast': 879, 'trade': 880, 'bad': 881, 'caused': 882, 'stray': 883, 'meaning': 884, 'damsel': 885, 'appear': 886, 'seven': 887, 'sentence': 888, 'jolly': 889, 'whenever': 890, 'wee': 891, 'wife': 892, 'lives': 893, 'martha': 894, 'courted': 895, 'bridgit': 896, 'omalley': 897, 'desolation': 898, 'thorn': 899, 'gaze': 900, 'stone': 901, 'approaching': 902, 'sets': 903, 'carrigfergus': 904, 'nights': 905, 'swim': 906, 'wings': 907, 'sober': 908, 'travel': 909, 'native': 910, 'places': 911, 'slopes': 912, 'hares': 913, 'lofty': 914, 'malone': 915, 'wheeled': 916, 'streets': 917, 'enough': 918, 'reilly': 919, 'tough': 920, 'whispers': 921, 'phil': 922, 'threw': 923, 'straight': 924, 'belles': 925, 'moor': 926, 'brand': 927, 'shapes': 928, 'work': 929, 'vow': 930, 'blarney': 931, 'paid': 932, 'bower': 933, 'remain': 934, 'charming': 935, 'storied': 936, 'chieftains': 937, 'slaughter': 938, 'bann': 939, 'boyne': 940, 'liffey': 941, 'gallant': 942, 'awake': 943, 'greet': 944, 'meadow': 945, 'sweeter': 946, 'dirty': 947, 'cats': 948, 'crossed': 949, 'field': 950, 'river': 951, 'full': 952, 'aroon': 953, 'sends': 954, 'woe': 955, 'chain': 956, 'main': 957, 'charms': 958, 'fondly': 959, 'fleet': 960, 'fairy': 961, 'thine': 962, 'known': 963, 'truly': 964, 'close': 965, 'story': 966, 'flag': 967, 'sweetest': 968, 'honor': 969, 'playing': 970, 'mauser': 971, 'music': 972, 'tom': 973, 'hurrah': 974, 'big': 975, 'lead': 976, 'south': 977, 'generation': 978, 'freedom': 979, 'agin': 980, 'creature': 981, 'dad': 982, 'venture': 983, 'word': 984, 'wonderful': 985, 'crazy': 986, 'lazy': 987, 'grave': 988, 'jest': 989, 'remark': 990, 'strangers': 991, 'strong': 992, 'shook': 993, 'walk': 994, 'north': 995, 'ours': 996, 'cease': 997, 'strife': 998, 'whats': 999, 'lilacs': 1000, 'prove': 1001, 'sweetheart': 1002, 'letters': 1003, 'sent': 1004, 'speak': 1005, 'brow': 1006, 'albert': 1007, 'mooney': 1008, 'fighting': 1009, 'fingers': 1010, 'toes': 1011, 'john': 1012, 'hurroo': 1013, 'drums': 1014, 'beguiled': 1015, 'carry': 1016, 'bone': 1017, 'havent': 1018, 'walkin': 1019, 'kilgary': 1020, 'pepper': 1021, 'countin': 1022, 'forth': 1023, 'deliver': 1024, 'daddy': 1025, 'em': 1026, 'deceive': 1027, 'between': 1028, 'even': 1029, 'prisoner': 1030, 'fists': 1031, 'knocked': 1032, 'carriages': 1033, 'rollin': 1034, 'juice': 1035, 'courtin': 1036, 'ponchartrain': 1037, 'does': 1038, 'stranger': 1039, 'marry': 1040, 'adieu': 1041, 'ask': 1042, 'tipped': 1043, 'arrived': 1044, 'ladies': 1045, 'potatoes': 1046, 'courting': 1047, 'miss': 1048, 'small': 1049, 'ned': 1050, 'ribbons': 1051, 'heel': 1052, 'bonny': 1053, 'pipe': 1054, 'thrush': 1055, 'sweethearts': 1056, 'unto': 1057, 'rise': 1058, 'softly': 1059, 'milking': 1060, 'rare': 1061, 'pity': 1062, 'treasure': 1063, 'noon': 1064, 'sailing': 1065, 'banish': 1066, 'riches': 1067, 'comfort': 1068, 'yonder': 1069, 'flows': 1070, 'fairer': 1071, 'lass': 1072, 'woods': 1073, 'strayed': 1074, 'locks': 1075, 'breaking': 1076, 'june': 1077, 'started': 1078, 'hearted': 1079, 'beer': 1080, 'daylight': 1081, 'among': 1082, 'bundle': 1083, 'connaught': 1084, 'quay': 1085, 'erins': 1086, 'galway': 1087, 'fearless': 1088, 'bravely': 1089, 'marches': 1090, 'fate': 1091, 'neck': 1092, 'trod': 1093, 'marched': 1094, 'antrim': 1095, 'sash': 1096, 'flashed': 1097, 'hath': 1098, 'foemans': 1099, 'fight': 1100, 'heavy': 1101, 'bore': 1102, 'mans': 1103, 'counter': 1104, 'dozen': 1105, 'gallon': 1106, 'bottles': 1107, 'diamond': 1108, 'resemble': 1109, 'tiny': 1110, 'friendly': 1111, 'weather': 1112, 'inside': 1113, 'remember': 1114, 'someone': 1115, 'hat': 1116, 'body': 1117, 'dancers': 1118, 'hanging': 1119, 'empty': 1120, 'shoes': 1121, 'broke': 1122, 'december': 1123, 'move': 1124, 'reason': 1125, 'roof': 1126, 'naught': 1127, 'tower': 1128, 'power': 1129, 'king': 1130, 'dreaming': 1131, 'crew': 1132, 'whos': 1133, 'mccann': 1134, 'smoke': 1135, 'notes': 1136, 'yeoman': 1137, 'cavalry': 1138, 'guard': 1139, 'forced': 1140, 'brother': 1141, 'cousin': 1142, 'blame': 1143, 'croppy': 1144, 'dressed': 1145, 'trees': 1146, 'wore': 1147, 'words': 1148, 'swiftly': 1149, 'dawn': 1150, 'lovd': 1151, 'voices': 1152, 'moaning': 1153, 'dark': 1154, 'gather': 1155, 'tay': 1156, 'swinging': 1157, 'drinkin': 1158, 'sitting': 1159, 'stile': 1160, 'springing': 1161, 'yours': 1162, 'kept': 1163, 'aisey': 1164, 'rub': 1165, 'dub': 1166, 'dow': 1167, 'shelah': 1168, 'fairly': 1169, 'beggarman': 1170, 'begging': 1171, 'slept': 1172, 'holes': 1173, 'coming': 1174, 'thru': 1175, 'boo': 1176, 'lady': 1177, 'kerry': 1178, 'pipers': 1179, 'laugh': 1180, 'beaming': 1181, 'guineas': 1182, 'least': 1183, 'diggin': 1184, 'mourne': 1185, 'spending': 1186, 'mellow': 1187, 'plying': 1188, 'slowly': 1189, 'mooncoin': 1190, 'flow': 1191, 'sounds': 1192, 'shine': 1193, 'cool': 1194, 'crystal': 1195, 'fountain': 1196, 'moonlight': 1197, 'grandmother': 1198, 'crooning': 1199, 'merrily': 1200, 'spins': 1201, 'lightly': 1202, 'moving': 1203, 'lattice': 1204, 'grove': 1205, 'swings': 1206, 'finger': 1207, 'shamrock': 1208, 'pocket': 1209, 'springtime': 1210, 'gilgarra': 1211, 'rapier': 1212, 'ringum': 1213, 'mornin': 1214, 'heather': 1215, 'build': 1216, 'maidens': 1217, 'prime': 1218, 'nlyme': 1219, 'flavours': 1220, 'lusty': 1221, 'reminded': 1222, 'attend': 1223, 'guardian': 1224, 'creeping': 1225, 'dale': 1226, 'vigil': 1227, 'visions': 1228, 'revealing': 1229, 'breathes': 1230, 'holy': 1231, 'strains': 1232, 'hover': 1233, 'hark': 1234, 'solemn': 1235, 'winging': 1236, 'earthly': 1237, 'shalt': 1238, 'awaken': 1239, 'destiny': 1240, 'emigrants': 1241, 'amid': 1242, 'longing': 1243, 'parted': 1244, 'townland': 1245, 'vessel': 1246, 'crowded': 1247, 'disquieted': 1248, 'folk': 1249, 'escape': 1250, 'hardship': 1251, 'sustaining': 1252, 'glimpse': 1253, 'faded': 1254, 'strangely': 1255, 'seas': 1256, 'anger': 1257, 'desperate': 1258, 'plight': 1259, 'worsened': 1260, 'delirium': 1261, 'possessed': 1262, 'clouded': 1263, 'prayers': 1264, 'begged': 1265, 'forgiveness': 1266, 'seeking': 1267, 'distant': 1268, 'mither': 1269, 'simple': 1270, 'ditty': 1271, 'ld': 1272, 'li': 1273, 'hush': 1274, 'lullaby': 1275, 'huggin': 1276, 'hummin': 1277, 'rock': 1278, 'asleep': 1279, 'outside': 1280, 'modestly': 1281, 'ry': 1282, 'ay': 1283, 'di': 1284, 're': 1285, 'dai': 1286, 'rie': 1287, 'shc': 1288, 'bridle': 1289, 'stable': 1290, 'oats': 1291, 'eat': 1292, 'soldier': 1293, 'aisy': 1294, 'arose': 1295, 'christmas': 1296, '1803': 1297, 'australia': 1298, 'marks': 1299, 'carried': 1300, 'rusty': 1301, 'iron': 1302, 'wains': 1303, 'mainsails': 1304, 'unfurled': 1305, 'curses': 1306, 'hurled': 1307, 'swell': 1308, 'moth': 1309, 'firelights': 1310, 'horses': 1311, 'rode': 1312, 'taking': 1313, 'hades': 1314, 'twilight': 1315, 'forty': 1316, 'slime': 1317, 'climate': 1318, 'bravery': 1319, 'ended': 1320, 'bond': 1321, 'rebel': 1322, 'iii': 1323, 'violin': 1324, 'clay': 1325, 'sooner': 1326, 'sport': 1327, 'colour': 1328, 'knows': 1329, 'earth': 1330, 'serve': 1331, 'clyde': 1332, 'mourn': 1333, 'weep': 1334, 'suffer': 1335, 'diamonds': 1336, 'queen': 1337, 'hung': 1338, 'tied': 1339, 'apprenticed': 1340, 'happiness': 1341, 'misfortune': 1342, 'follow': 1343, 'strolling': 1344, 'selling': 1345, 'bar': 1346, 'customer': 1347, 'slipped': 1348, 'luck': 1349, 'jury': 1350, 'trial': 1351, 'case': 1352, 'warning': 1353, 'liquor': 1354, 'porter': 1355, 'pleasures': 1356, 'fishing': 1357, 'farming': 1358, 'glens': 1359, 'softest': 1360, 'dripping': 1361, 'snare': 1362, 'lose': 1363, 'court': 1364, 'primrose': 1365, 'bee': 1366, 'hopeless': 1367, 'wonders': 1368, 'admiration': 1369, 'haunt': 1370, 'wherever': 1371, 'sands': 1372, 'purer': 1373, 'within': 1374, 'grieve': 1375, 'drumslieve': 1376, 'ballygrant': 1377, 'deepest': 1378, 'boatsman': 1379, 'ferry': 1380, 'childhood': 1381, 'reflections': 1382, 'boyhood': 1383, 'melting': 1384, 'roaming': 1385, 'reported': 1386, 'marble': 1387, 'stones': 1388, 'ink': 1389, 'support': 1390, 'drunk': 1391, 'seldom': 1392, 'sick': 1393, 'numbered': 1394, 'foam': 1395, 'compare': 1396, 'sights': 1397, 'coast': 1398, 'clare': 1399, 'kilkee': 1400, 'kilrush': 1401, 'watching': 1402, 'pheasants': 1403, 'homes': 1404, 'streams': 1405, 'dublins': 1406, 'cockles': 1407, 'mussels': 1408, 'fish': 1409, 'monger': 1410, 'ghost': 1411, 'wheels': 1412, 'eden': 1413, 'vanished': 1414, 'finea': 1415, 'halfway': 1416, 'cootehill': 1417, 'gruff': 1418, 'whispering': 1419, 'crow': 1420, 'newborn': 1421, 'babies': 1422, 'huff': 1423, 'start': 1424, 'sorrowful': 1425, 'squall': 1426, 'babys': 1427, 'toil': 1428, 'worn': 1429, 'fore': 1430, 'flute': 1431, 'yer': 1432, 'boot': 1433, 'magee': 1434, 'scruff': 1435, 'slanderin': 1436, 'marchin': 1437, 'assisted': 1438, 'drain': 1439, 'dudeen': 1440, 'puff': 1441, 'whisperings': 1442, 'barrin': 1443, 'chocolate': 1444, 'feegee': 1445, 'sort': 1446, 'moonshiny': 1447, 'stuff': 1448, 'addle': 1449, 'brain': 1450, 'ringin': 1451, 'glamour': 1452, 'gas': 1453, 'guff': 1454, 'whisper': 1455, 'oil': 1456, 'remarkable': 1457, 'policeman': 1458, 'bluff': 1459, 'maintain': 1460, 'guril': 1461, 'sic': 1462, 'passage': 1463, 'rough': 1464, 'borne': 1465, 'breeze': 1466, 'boundless': 1467, 'stupendous': 1468, 'roll': 1469, 'thundering': 1470, 'motion': 1471, 'mermaids': 1472, 'fierce': 1473, 'tempest': 1474, 'gathers': 1475, 'oneill': 1476, 'odonnell': 1477, 'lucan': 1478, 'oconnell': 1479, 'brian': 1480, 'drove': 1481, 'danes': 1482, 'patrick': 1483, 'vermin': 1484, 'whose': 1485, 'benburb': 1486, 'blackwater': 1487, 'owen': 1488, 'roe': 1489, 'munroe': 1490, 'lambs': 1491, 'skip': 1492, 'views': 1493, 'enchanting': 1494, 'rostrevor': 1495, 'groves': 1496, 'lakes': 1497, 'ride': 1498, 'tide': 1499, 'majestic': 1500, 'shannon': 1501, 'sail': 1502, 'loch': 1503, 'neagh': 1504, 'ross': 1505, 'gorey': 1506, 'saxon': 1507, 'tory': 1508, 'soil': 1509, 'sanctified': 1510, 'enemies': 1511, 'links': 1512, 'encumbered': 1513, 'resound': 1514, 'hosannahs': 1515, 'bide': 1516, 'hushed': 1517, 'lying': 1518, 'kneel': 1519, 'ave': 1520, 'tread': 1521, 'fail': 1522, 'simply': 1523, 'gasworks': 1524, 'croft': 1525, 'dreamed': 1526, 'canal': 1527, 'factory': 1528, 'clouds': 1529, 'drifting': 1530, 'prowling': 1531, 'beat': 1532, 'springs': 1533, 'siren': 1534, 'docks': 1535, 'train': 1536, 'smelled': 1537, 'smokey': 1538, 'sharp': 1539, 'axe': 1540, 'steel': 1541, 'tempered': 1542, 'chop': 1543, 't': 1544, 'agree': 1545, 'leaning': 1546, 'weirs': 1547, 'ray': 1548, 'glow': 1549, 'changeless': 1550, 'constant': 1551, 'bounding': 1552, 'castles': 1553, 'sacked': 1554, 'scattered': 1555, 'fixed': 1556, 'endearing': 1557, 'gifts': 1558, 'fading': 1559, 'wouldst': 1560, 'adored': 1561, 'loveliness': 1562, 'ruin': 1563, 'itself': 1564, 'verdantly': 1565, 'unprofaned': 1566, 'fervor': 1567, 'faith': 1568, 'forgets': 1569, 'sunflower': 1570, 'rag': 1571, 'games': 1572, 'hold': 1573, 'defend': 1574, 'veteran': 1575, 'volunteers': 1576, 'pat': 1577, 'pearse': 1578, 'clark': 1579, 'macdonagh': 1580, 'macdiarmada': 1581, 'mcbryde': 1582, 'james': 1583, 'connolly': 1584, 'placed': 1585, 'machine': 1586, 'ranting': 1587, 'hour': 1588, 'bullet': 1589, 'stuck': 1590, 'craw': 1591, 'poisoning': 1592, 'ceannt': 1593, 'lions': 1594, 'union': 1595, 'poured': 1596, 'dismay': 1597, 'horror': 1598, 'englishmen': 1599, 'khaki': 1600, 'renown': 1601, 'fame': 1602, 'forefathers': 1603, 'blaze': 1604, 'priests': 1605, 'offer': 1606, 'charmin': 1607, 'variety': 1608, 'renownd': 1609, 'learnin': 1610, 'piety': 1611, 'advance': 1612, 'widout': 1613, 'impropriety': 1614, 'flowr': 1615, 'cho': 1616, 'powrfulest': 1617, 'preacher': 1618, 'tenderest': 1619, 'teacher': 1620, 'kindliest': 1621, 'donegal': 1622, 'talk': 1623, 'provost': 1624, 'trinity': 1625, 'famous': 1626, 'greek': 1627, 'latinity': 1628, 'divils': 1629, 'divinity': 1630, 'd': 1631, 'likes': 1632, 'logic': 1633, 'mythology': 1634, 'thayology': 1635, 'conchology': 1636, 'sinners': 1637, 'wishful': 1638, 'childer': 1639, 'avick': 1640, 'gad': 1641, 'flock': 1642, 'grandest': 1643, 'control': 1644, 'checking': 1645, 'coaxin': 1646, 'onaisy': 1647, 'lifting': 1648, 'avoidin': 1649, 'frivolity': 1650, 'seasons': 1651, 'innocent': 1652, 'jollity': 1653, 'playboy': 1654, 'claim': 1655, 'equality': 1656, 'comicality': 1657, 'bishop': 1658, 'lave': 1659, 'gaiety': 1660, 'laity': 1661, 'clergy': 1662, 'jewels': 1663, 'plundering': 1664, 'pillage': 1665, 'starved': 1666, 'cries': 1667, 'thems': 1668, 'bondage': 1669, 'fourth': 1670, 'tabhair': 1671, 'dom': 1672, 'lámh': 1673, 'harmony': 1674, 'east': 1675, 'destroy': 1676, 'command': 1677, 'gesture': 1678, 'troubles': 1679, 'weak': 1680, 'peoples': 1681, 'creeds': 1682, 'lets': 1683, 'needs': 1684, 'passion': 1685, 'fashion': 1686, 'guide': 1687, 'share': 1688, 'sparkling': 1689, 'meeting': 1690, 'iull': 1691, 'contented': 1692, 'ache': 1693, 'painful': 1694, 'wrote': 1695, 'twisted': 1696, 'twined': 1697, 'cheek': 1698, 'bedim': 1699, 'holds': 1700, 'smiles': 1701, 'scarcely': 1702, 'darkning': 1703, 'beyond': 1704, 'yearn': 1705, 'laughs': 1706, 'humble': 1707, 'brightest': 1708, 'gleam': 1709, 'forgot': 1710, 'pulled': 1711, 'comb': 1712, 'counting': 1713, 'knock': 1714, 'murray': 1715, 'fellow': 1716, 'hail': 1717, 'tumblin': 1718, 'apple': 1719, 'pie': 1720, 'gets': 1721, 'doleful': 1722, 'enemy': 1723, 'nearly': 1724, 'slew': 1725, 'queer': 1726, 'mild': 1727, 'legs': 1728, 'indeed': 1729, 'island': 1730, 'sulloon': 1731, 'flesh': 1732, 'yere': 1733, 'armless': 1734, 'boneless': 1735, 'chickenless': 1736, 'egg': 1737, 'yell': 1738, 'bowl': 1739, 'rolling': 1740, 'swearing': 1741, 'rattled': 1742, 'saber': 1743, 'deceiver': 1744, 'rig': 1745, 'um': 1746, 'du': 1747, 'rum': 1748, 'jar': 1749, 'shinin': 1750, 'coins': 1751, 'promised': 1752, 'vowed': 1753, 'devils': 1754, 'awakened': 1755, 'six': 1756, 'guards': 1757, 'numbers': 1758, 'odd': 1759, 'flew': 1760, 'mistaken': 1761, 'mollys': 1762, 'robbing': 1763, 'sentry': 1764, 'sligo': 1765, 'fishin': 1766, 'bowlin': 1767, 'others': 1768, 'railroad': 1769, 'ties': 1770, 'crossings': 1771, 'swamps': 1772, 'elevations': 1773, 'resolved': 1774, 'sunset': 1775, 'higher': 1776, 'win': 1777, 'allegators': 1778, 'wood': 1779, 'treated': 1780, 'shoulders': 1781, 'paint': 1782, 'picture': 1783, 'vain': 1784, 'returned': 1785, 'cottage': 1786, 'sociable': 1787, 'foaming': 1788, 'n': 1789, 'jeremy': 1790, 'lanigan': 1791, 'battered': 1792, 'hadnt': 1793, 'pound': 1794, 'farm': 1795, 'acres': 1796, 'party': 1797, 'listen': 1798, 'glisten': 1799, 'rows': 1800, 'ructions': 1801, 'invitation': 1802, 'minute': 1803, 'bees': 1804, 'cask': 1805, 'judy': 1806, 'odaly': 1807, 'milliner': 1808, 'wink': 1809, 'peggy': 1810, 'mcgilligan': 1811, 'lashings': 1812, 'punch': 1813, 'cakes': 1814, 'bacon': 1815, 'tea': 1816, 'nolans': 1817, 'dolans': 1818, 'ogradys': 1819, 'sounded': 1820, 'taras': 1821, 'hall': 1822, 'nelly': 1823, 'gray': 1824, 'rat': 1825, 'catchers': 1826, 'doing': 1827, 'kinds': 1828, 'nonsensical': 1829, 'polkas': 1830, 'whirligig': 1831, 'julia': 1832, 'banished': 1833, 'nonsense': 1834, 'twist': 1835, 'jig': 1836, 'mavrone': 1837, 'mad': 1838, 'ceiling': 1839, 'brooks': 1840, 'academy': 1841, 'learning': 1842, 'learn': 1843, 'couples': 1844, 'groups': 1845, 'accident': 1846, 'happened': 1847, 'terrance': 1848, 'mccarthy': 1849, 'finnertys': 1850, 'hoops': 1851, 'cried': 1852, 'meelia': 1853, 'murther': 1854, 'gathered': 1855, 'carmody': 1856, 'further': 1857, 'satisfaction': 1858, 'midst': 1859, 'kerrigan': 1860, 'declared': 1861, 'painted': 1862, 'suppose': 1863, 'morgan': 1864, 'powerful': 1865, 'stretched': 1866, 'smashed': 1867, 'chaneys': 1868, 'runctions': 1869, 'lick': 1870, 'phelim': 1871, 'mchugh': 1872, 'replied': 1873, 'introduction': 1874, 'kicked': 1875, 'terrible': 1876, 'hullabaloo': 1877, 'piper': 1878, 'strangled': 1879, 'squeezed': 1880, 'bellows': 1881, 'chanters': 1882, 'entangled': 1883, 'gaily': 1884, 'mairis': 1885, 'hillways': 1886, 'myrtle': 1887, 'bracken': 1888, 'sheilings': 1889, 'sake': 1890, 'rowans': 1891, 'herring': 1892, 'meal': 1893, 'peat': 1894, 'creel': 1895, 'bairns': 1896, 'weel': 1897, 'toast': 1898, 'soar': 1899, 'blackbird': 1900, 'note': 1901, 'linnet': 1902, 'lure': 1903, 'cozy': 1904, 'catch': 1905, 'company': 1906, 'harm': 1907, 'wit': 1908, 'recall': 1909, 'leisure': 1910, 'awhile': 1911, 'sorely': 1912, 'ruby': 1913, 'enthralled': 1914, 'sorry': 1915, 'theyd': 1916, 'falls': 1917, 'lot': 1918, 'tuned': 1919, 'bough': 1920, 'cow': 1921, 'chanting': 1922, 'melodious': 1923, 'scarce': 1924, 'soothed': 1925, 'solace': 1926, 'courtesy': 1927, 'salute': 1928, 'amiable': 1929, 'captive': 1930, 'slave': 1931, 'future': 1932, 'banter': 1933, 'enamour': 1934, 'indies': 1935, 'afford': 1936, 'transparently': 1937, 'flame': 1938, 'add': 1939, 'fuel': 1940, 'grant': 1941, 'desire': 1942, 'expire': 1943, 'wealth': 1944, 'damer': 1945, 'african': 1946, 'devonshire': 1947, 'lamp': 1948, 'alladin': 1949, 'genie': 1950, 'also': 1951, 'withdraw': 1952, 'tease': 1953, 'single': 1954, 'airy': 1955, 'embarrass': 1956, 'besides': 1957, 'almanack': 1958, 'useless': 1959, 'date': 1960, 'ware': 1961, 'rate': 1962, 'fragrance': 1963, 'loses': 1964, 'consumed': 1965, 'october': 1966, 'knowing': 1967, 'steer': 1968, 'blast': 1969, 'danger': 1970, 'farthing': 1971, 'affection': 1972, 'enjoy': 1973, 'choose': 1974, 'killarneys': 1975, 'sister': 1976, 'pains': 1977, 'loss': 1978, 'tuam': 1979, 'saluted': 1980, 'drank': 1981, 'pint': 1982, 'smother': 1983, 'reap': 1984, 'cut': 1985, 'goblins': 1986, 'bought': 1987, 'brogues': 1988, 'rattling': 1989, 'bogs': 1990, 'frightning': 1991, 'dogs': 1992, 'hunt': 1993, 'hare': 1994, 'follol': 1995, 'rah': 1996, 'mullingar': 1997, 'rested': 1998, 'limbs': 1999, 'blithe': 2000, 'heartfrom': 2001, 'paddys': 2002, 'cure': 2003, 'lassies': 2004, 'laughing': 2005, 'curious': 2006, 'style': 2007, 'twould': 2008, 'bubblin': 2009, 'hired': 2010, 'wages': 2011, 'required': 2012, 'almost': 2013, 'deprived': 2014, 'stroll': 2015, 'quality': 2016, 'locality': 2017, 'something': 2018, 'wobblin': 2019, 'enquiring': 2020, 'rogue': 2021, 'brogue': 2022, 'wasnt': 2023, 'vogue': 2024, 'spirits': 2025, 'falling': 2026, 'jumped': 2027, 'aboard': 2028, 'pigs': 2029, 'rigs': 2030, 'jigs': 2031, 'bubbling': 2032, 'holyhead': 2033, 'wished': 2034, 'instead': 2035, 'bouys': 2036, 'liverpool': 2037, 'safely': 2038, 'fool': 2039, 'boil': 2040, 'temper': 2041, 'losing': 2042, 'abusing': 2043, 'shillelagh': 2044, 'nigh': 2045, 'hobble': 2046, 'load': 2047, 'hurray': 2048, 'joined': 2049, 'affray': 2050, 'quitely': 2051, 'cleared': 2052, 'host': 2053, 'march': 2054, 'faces': 2055, 'farmstead': 2056, 'fishers': 2057, 'ban': 2058, 'vengeance': 2059, 'hapless': 2060, 'about': 2061, 'hemp': 2062, 'rope': 2063, 'clung': 2064, 'grim': 2065, 'array': 2066, 'earnest': 2067, 'stalwart': 2068, 'stainless': 2069, 'banner': 2070, 'marching': 2071, 'torn': 2072, 'furious': 2073, 'odds': 2074, 'keen': 2075, 'toomebridge': 2076, 'treads': 2077, 'upwards': 2078, 'traveled': 2079, 'quarters': 2080, 'below': 2081, 'hogshead': 2082, 'stack': 2083, 'stagger': 2084, 'dig': 2085, 'hole': 2086, 'couple': 2087, 'scratch': 2088, 'consolation': 2089, 'tyrant': 2090, 'remorseless': 2091, 'foe': 2092, 'lift': 2093, 'stranded': 2094, 'prince': 2095, 'edward': 2096, 'coffee': 2097, 'trace': 2098, 'fiddlin': 2099, 'dime': 2100, 'shy': 2101, 'hello': 2102, 'wintry': 2103, 'yellow': 2104, 'somewhere': 2105, 'written': 2106, 'begin': 2107, 'tap': 2108, 'caught': 2109, 'leap': 2110, 'clumsy': 2111, 'graceful': 2112, 'fiddlers': 2113, 'everywhere': 2114, 'boots': 2115, 'laughtcr': 2116, 'suits': 2117, 'easter': 2118, 'gowns': 2119, 'sailors': 2120, 'pianos': 2121, 'setting': 2122, 'someones': 2123, 'hats': 2124, 'rack': 2125, 'chair': 2126, 'wooden': 2127, 'feels': 2128, 'touch': 2129, 'awaitin': 2130, 'thc': 2131, 'fiddles': 2132, 'closet': 2133, 'strings': 2134, 'tbe': 2135, 'covers': 2136, 'buttoned': 2137, 'sometimes': 2138, 'melody': 2139, 'passes': 2140, 'slight': 2141, 'lack': 2142, 'moved': 2143, 'homeward': 2144, 'swan': 2145, 'moves': 2146, 'goods': 2147, 'gear': 2148, 'din': 2149, 'rude': 2150, 'wherein': 2151, 'dwell': 2152, 'abandon': 2153, 'energy': 2154, 'blight': 2155, 'praties': 2156, 'sheep': 2157, 'cattle': 2158, 'taxes': 2159, 'unpaid': 2160, 'redeem': 2161, 'bleak': 2162, 'landlord': 2163, 'sheriff': 2164, 'spleen': 2165, 'heaved': 2166, 'sigh': 2167, 'bade': 2168, 'goodbye': 2169, 'stony': 2170, 'anguish': 2171, 'seeing': 2172, 'feeble': 2173, 'frame': 2174, 'wrapped': 2175, 'c�ta': 2176, 'm�r': 2177, 'unseen': 2178, 'stern': 2179, 'rally': 2180, 'cheer': 2181, 'revenge': 2182, 'waking': 2183, 'wisdom': 2184, 'dwelling': 2185, 'battleshield': 2186, 'dignity': 2187, 'shelter': 2188, 'heed': 2189, 'inheritance': 2190, 'heavem': 2191, 'heaven': 2192, 'victory': 2193, 'reach': 2194, 'whatever': 2195, 'befall': 2196, 'ruler': 2197, 'pleasant': 2198, 'rambling': 2199, 'board': 2200, 'followed': 2201, 'shortly': 2202, 'anchor': 2203, '23rd': 2204, 'lrelands': 2205, 'daughters': 2206, 'crowds': 2207, 'assembled': 2208, 'fulfill': 2209, 'jovial': 2210, 'conversations': 2211, 'neighbors': 2212, 'turning': 2213, 'tailor': 2214, 'quigley': 2215, 'bould': 2216, 'britches': 2217, 'lived': 2218, 'flying': 2219, 'dove': 2220, 'hiii': 2221, 'dreamt': 2222, 'joking': 2223, 'manys': 2224, 'cock': 2225, 'shrill': 2226, 'awoke': 2227, 'california': 2228, 'miles': 2229, 'banbridge': 2230, 'july': 2231, 'boreen': 2232, 'sheen': 2233, 'coaxing': 2234, 'elf': 2235, 'shake': 2236, 'bantry': 2237, 'onward': 2238, 'sped': 2239, 'gazed': 2240, 'passerby': 2241, 'gem': 2242, 'irelands': 2243, 'travelled': 2244, 'hit': 2245, 'career': 2246, 'square': 2247, 'surrendered': 2248, 'tenant': 2249, 'shawl': 2250, 'gown': 2251, 'crossroads': 2252, 'dress': 2253, 'try': 2254, 'sheeps': 2255, 'deludhering': 2256, 'yoke': 2257, 'rust': 2258, 'plow': 2259, 'fireside': 2260, 'sits': 2261, 'whistle': 2262, 'changing': 2263, 'fright': 2264, 'downfall': 2265, 'cornwall': 2266, 'parlour': 2267, 'passing': 2268, 'william': 2269, 'betray': 2270, 'guinea': 2271, 'walking': 2272, 'mounted': 2273, 'platform': 2274, 'deny': 2275, 'walked': 2276, 'margin': 2277, 'lough': 2278, 'leane': 2279, 'bloomed': 2280, 'whom': 2281, 'cap': 2282, 'cloak': 2283, 'glossy': 2284, 'pail': 2285, 'palm': 2286, 'venus': 2287, 'bank': 2288, 'travelians': 2289, 'babes': 2290, 'freebirds': 2291, 'grew': 2292, 'matters': 2293, 'famine': 2294, 'rebelled': 2295, 'windswept': 2296, 'harbour': 2297, 'botany': 2298, 'whilst': 2299, 'wan': 2300, 'cloud': 2301, 'shannons': 2302, 'returnd': 2303, 'doubts': 2304, 'fears': 2305, 'aching': 2306, 'seemd': 2307, 'mingling': 2308, 'flood': 2309, 'path': 2310, 'wrath': 2311, 'lamenting': 2312, 'sudden': 2313, 'kissd': 2314, 'showrs': 2315, 'flowing': 2316, 'laughd': 2317, 'beam': 2318, 'soared': 2319, 'aloft': 2320, 'phantom': 2321, 'outspread': 2322, 'throbbing': 2323, 'hid': 2324, 'treasures': 2325, 'pots': 2326, 'tin': 2327, 'cans': 2328, 'mash': 2329, 'bran': 2330, 'barney': 2331, 'peeled': 2332, 'searching': 2333, 'connemara': 2334, 'butcher': 2335, 'quart': 2336, 'bottle': 2337, 'help': 2338, 'gate': 2339, 'glory': 2340, 'lane': 2341, 'village': 2342, 'church': 2343, 'spire': 2344, 'graveyard': 2345, 'baby': 2346, 'blessing': 2347, 'hoping': 2348, 'trust': 2349, 'strength': 2350, 'thank': 2351, 'bidding': 2352, 'bread': 2353, 'shines': 2354, 'fifty': 2355, 'often': 2356, 'shut': 2357, 'frisky': 2358, 'pig': 2359, 'whisky': 2360, 'uncle': 2361, 'enlisted': 2362, 'trudged': 2363, 'bosom': 2364, 'daisy': 2365, 'drubbing': 2366, 'shirts': 2367, 'battle': 2368, 'blows': 2369, 'pate': 2370, 'bothered': 2371, 'rarely': 2372, 'dropped': 2373, 'honest': 2374, 'thinks': 2375, 'eight': 2376, 'score': 2377, 'basin': 2378, 'zoo': 2379, 'everybody': 2380, 'calls': 2381, 'trades': 2382, 'dinner': 2383, 'slip': 2384, 'corner': 2385, 'barn': 2386, 'currabawn': 2387, 'shocking': 2388, 'wet': 2389, 'raindrops': 2390, 'rats': 2391, 'peek': 2392, 'waken': 2393, 'spotted': 2394, 'apron': 2395, 'calico': 2396, 'blouse': 2397, 'frighten': 2398, 'afraid': 2399, 'flaxen': 2400, 'haired': 2401, 'rags': 2402, 'tags': 2403, 'leggins': 2404, 'collar': 2405, 'tie': 2406, 'goggles': 2407, 'fashioned': 2408, 'bag': 2409, 'bulging': 2410, 'sack': 2411, 'peeping': 2412, 'skin': 2413, 'rink': 2414, 'doodle': 2415, 'getting': 2416, 'raked': 2417, 'gladness': 2418, 'tuning': 2419, 'fills': 2420, 'eily': 2421, 'prouder': 2422, 'thady': 2423, 'boldly': 2424, 'lasses': 2425, 'fled': 2426, 'silent': 2427, 'glad': 2428, 'echo': 2429, 'companions': 2430, 'soars': 2431, 'enchanted': 2432, 'granted': 2433, 'adoration': 2434, 'gives': 2435, 'joyous': 2436, 'elation': 2437, 'covered': 2438, 'winter': 2439, 'riding': 2440, 'cherry': 2441, 'coal': 2442, 'falter': 2443, 'bowed': 2444, 'bonnet': 2445, 'courteous': 2446, 'looks': 2447, 'engaging': 2448, 'sell': 2449, 'purse': 2450, 'yearly': 2451, 'need': 2452, 'market': 2453, 'gain': 2454, 'dearly': 2455, 'tarry': 2456, 'although': 2457, 'parlay': 2458, 'ranks': 2459, 'girded': 2460, 'slung': 2461, 'warrior': 2462, 'bard': 2463, 'betrays': 2464, 'rights': 2465, 'faithful': 2466, 'chords': 2467, 'asunder': 2468, 'sully': 2469, 'bravry': 2470, 'londons': 2471, 'sight': 2472, 'workin': 2473, 'sow': 2474, 'wheat': 2475, 'gangs': 2476, 'sweep': 2477, 'expressed': 2478, 'london': 2479, 'top': 2480, 'dresses': 2481, 'bath': 2482, 'startin': 2483, 'fashions': 2484, 'mccree': 2485, 'nature': 2486, 'designed': 2487, 'complexions': 2488, 'cream': 2489, 'regard': 2490, 'sip': 2491, 'colors': 2492, 'wait': 2493, 'waitin': 2494, 'sweeps': 2495, 'beauing': 2496, 'belling': 2497, 'windows': 2498, 'cursing': 2499, 'faster': 2500, 'waiters': 2501, 'bailiffs': 2502, 'duns': 2503, 'bacchus': 2504, 'begotten': 2505, 'politicians': 2506, 'funds': 2507, 'dadda': 2508, 'living': 2509, 'drives': 2510, 'having': 2511, 'racking': 2512, 'tenants': 2513, 'stewards': 2514, 'teasing': 2515, 'raising': 2516, 'wishing': 2517, 'sunny': 2518, 'doves': 2519, 'coo': 2520, 'neath': 2521, 'sunbeam': 2522, 'robin': 2523, 'waters': 2524, 'larks': 2525, 'join': 2526, 'breaks': 2527, 'oftimes': 2528, 'lilies': 2529, 'declining': 2530, 'vale': 2531, 'shades': 2532, 'mantle': 2533, 'spreading': 2534, 'listening': 2535, 'shedding': 2536, 'beginning': 2537, 'spinning': 2538, 'blind': 2539, 'drowsily': 2540, 'knitting': 2541, 'cheerily': 2542, 'noiselessly': 2543, 'whirring': 2544, 'foots': 2545, 'stirring': 2546, 'sprightly': 2547, 'chara': 2548, 'tapping': 2549, 'ivy': 2550, 'flapping': 2551, 'somebody': 2552, 'sighing': 2553, 'autumn': 2554, 'noise': 2555, 'chirping': 2556, 'holly': 2557, 'shoving': 2558, 'wrong': 2559, 'coolin': 2560, 'casement': 2561, 'rove': 2562, 'moons': 2563, 'brightly': 2564, 'shakes': 2565, 'lays': 2566, 'longs': 2567, 'lingers': 2568, 'glance': 2569, 'puts': 2570, 'lazily': 2571, 'easily': 2572, 'lowly': 2573, 'reels': 2574, 'noiseless': 2575, 'leaps': 2576, 'ere': 2577, 'lovers': 2578, 'roved': 2579, 'verdant': 2580, 'braes': 2581, 'skreen': 2582, 'countrie': 2583, 'foreign': 2584, 'strand': 2585, 'dewy': 2586, 'climb': 2587, 'rob': 2588, 'boat': 2589, 'sails': 2590, 'loaded': 2591, 'sink': 2592, 'leaned': 2593, 'oak': 2594, 'trusty': 2595, 'false': 2596, 'reached': 2597, 'pricked': 2598, 'waxes': 2599, 'fades': 2600, 'wholl': 2601, 'cockle': 2602, 'gloom': 2603, 'news': 2604, 'forbid': 2605, 'patricks': 2606, 'napper': 2607, 'tandy': 2608, 'hows': 2609, 'distressful': 2610, 'englands': 2611, 'remind': 2612, 'pull': 2613, 'throw': 2614, 'sod': 2615, 'root': 2616, 'underfoot': 2617, 'laws': 2618, 'blades': 2619, 'growin': 2620, 'dare': 2621, 'show': 2622, 'caubeen': 2623, 'year': 2624, 'returning': 2625, 'store': 2626, 'ale': 2627, 'frequent': 2628, 'landlady': 2629, 'credit': 2630, 'custom': 2631, 'sovereigns': 2632, 'landladys': 2633, 'wines': 2634, 'confess': 2635, 'pardon': 2636, 'prodigal': 2637, 'caress': 2638, 'forgive': 2639, 'ofttimes': 2640, 'wondering': 2641, 'powr': 2642, 'beguile': 2643, 'teardrop': 2644, 'lilting': 2645, 'laughters': 2646, 'twinkle': 2647, 'lilt': 2648, 'seems': 2649, 'linnets': 2650, 'real': 2651, 'regret': 2652, 'throughout': 2653, 'youths': 2654, 'chance': 2655, 'spied': 2656, 'receiver': 2657, 'counted': 2658, 'penny': 2659, 'bu': 2660, 'rungum': 2661, 'chamber': 2662, 'course': 2663, 'charges': 2664, 'filled': 2665, 'ready': 2666, 'footmen': 2667, 'likewise': 2668, 'draw': 2669, 'pistol': 2670, 'couldnt': 2671, 'shoot': 2672, 'robbin': 2673, 'jailer': 2674, 'tight': 2675, 'fisted': 2676, 'army': 2677, 'stationed': 2678, 'cork': 2679, 'roamin': 2680, 'swear': 2681, 'treat': 2682, 'sportin': 2683, 'hurley': 2684, 'bollin': 2685, 'maids': 2686, 'summertime': 2687, 'pluck': 2688, 'yon': 2689}\n",
            "2690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJaRBfVUOlaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bMAXKo6PP94",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "46b790a5-b220-4b26-8d7b-88102c5b2781"
      },
      "source": [
        "print(tokenizer.word_index['in'])\n",
        "print(tokenizer.word_index['the'])\n",
        "print(tokenizer.word_index['town'])\n",
        "print(tokenizer.word_index['of'])\n",
        "print(tokenizer.word_index['athy'])\n",
        "print(tokenizer.word_index['one'])\n",
        "print(tokenizer.word_index['jeremy'])\n",
        "print(tokenizer.word_index['lanigan'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "1\n",
            "71\n",
            "6\n",
            "713\n",
            "39\n",
            "1790\n",
            "1791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NsYdOGIPbhv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f800f5ac-1923-4e06-a834-d7bc52a4351f"
      },
      "source": [
        "print(xs[7])\n",
        "print(ys[7])\n",
        "print(xs[8])\n",
        "print(ys[8])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  2 11]\n",
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  2 11 15]\n",
            "[0. 0. 0. ... 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0teT9PAP65h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "81a7e379-abfb-497e-8320-45130b397eaa"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 1, 'and': 2, 'i': 3, 'to': 4, 'a': 5, 'of': 6, 'my': 7, 'in': 8, 'me': 9, 'for': 10, 'you': 11, 'all': 12, 'was': 13, 'she': 14, 'that': 15, 'on': 16, 'with': 17, 'her': 18, 'but': 19, 'as': 20, 'when': 21, 'love': 22, 'is': 23, 'your': 24, 'it': 25, 'will': 26, 'from': 27, 'by': 28, 'they': 29, 'be': 30, 'are': 31, 'so': 32, 'he': 33, 'old': 34, 'no': 35, 'oh': 36, 'ill': 37, 'at': 38, 'one': 39, 'his': 40, 'there': 41, 'were': 42, 'heart': 43, 'down': 44, 'now': 45, 'we': 46, 'where': 47, 'young': 48, 'never': 49, 'go': 50, 'come': 51, 'then': 52, 'did': 53, 'not': 54, 'said': 55, 'away': 56, 'their': 57, 'sweet': 58, 'them': 59, 'green': 60, 'if': 61, 'take': 62, 'our': 63, 'like': 64, 'night': 65, 'day': 66, 'o': 67, 'out': 68, 'fair': 69, 'this': 70, 'town': 71, 'have': 72, 'can': 73, 'true': 74, 'its': 75, 'thou': 76, 'see': 77, 'dear': 78, 'more': 79, 'theres': 80, 'or': 81, 'had': 82, 'would': 83, 'over': 84, 'hear': 85, 'up': 86, 'ive': 87, 'through': 88, 'home': 89, 'again': 90, 'well': 91, 'oer': 92, 'land': 93, 'good': 94, 'im': 95, 'ye': 96, 'sea': 97, 'left': 98, 'still': 99, 'father': 100, 'long': 101, 'rose': 102, 'could': 103, 'morning': 104, 'wild': 105, 'who': 106, 'eyes': 107, 'came': 108, 'while': 109, 'too': 110, 'back': 111, 'little': 112, 'an': 113, 'took': 114, 'him': 115, 'bow': 116, 'first': 117, 'let': 118, 'man': 119, 'shall': 120, 'know': 121, 'get': 122, 'high': 123, 'gone': 124, 'say': 125, 'ever': 126, 'some': 127, 'mary': 128, 'hand': 129, 'till': 130, 'put': 131, 'own': 132, 'time': 133, 'heard': 134, 'dead': 135, 'may': 136, 'bright': 137, 'mountain': 138, 'early': 139, 'rosin': 140, 'gave': 141, 'thee': 142, 'only': 143, 'far': 144, 'maid': 145, 'must': 146, 'find': 147, 'girl': 148, 'sure': 149, 'round': 150, 'dublin': 151, 'once': 152, 'world': 153, 'delight': 154, 'last': 155, 'johnny': 156, 'seen': 157, 'has': 158, 'fine': 159, 'road': 160, 'mother': 161, 'tis': 162, 'what': 163, 'way': 164, 'moon': 165, 'soul': 166, 'neer': 167, 'id': 168, 'just': 169, 'thats': 170, 'days': 171, 'darling': 172, 'went': 173, 'white': 174, 'die': 175, 'than': 176, 'hair': 177, 'goes': 178, 'meet': 179, 'today': 180, 'do': 181, 'girls': 182, 'shes': 183, 'thyme': 184, 'thy': 185, 'sing': 186, 'pretty': 187, 'new': 188, 'poor': 189, 'into': 190, 'life': 191, 'irish': 192, 'give': 193, 'boy': 194, 'youre': 195, 'make': 196, 'passed': 197, 'lovely': 198, 'black': 199, 'youll': 200, 'died': 201, 'red': 202, 'smile': 203, 'keep': 204, 'loves': 205, 'free': 206, 'leave': 207, 'friends': 208, 'each': 209, 'saw': 210, 'behind': 211, 'song': 212, 'ra': 213, 'dont': 214, 'arms': 215, 'am': 216, 'sun': 217, 'saying': 218, 'made': 219, 'wish': 220, 'cold': 221, 'met': 222, 'before': 223, 'should': 224, 'rocky': 225, 'light': 226, 'wid': 227, 'boys': 228, 'best': 229, 'fields': 230, 'since': 231, 'ball': 232, 'water': 233, 'casey': 234, 'mind': 235, 'along': 236, 'loved': 237, 'place': 238, 'ireland': 239, 'next': 240, 'three': 241, 'many': 242, 'years': 243, 'door': 244, 'us': 245, 'drink': 246, 'got': 247, 'might': 248, 'live': 249, 'roses': 250, 'play': 251, 'soon': 252, 'ground': 253, 'times': 254, 'spent': 255, 'going': 256, 'tree': 257, 'barley': 258, 'grass': 259, 'kind': 260, 'twas': 261, 'bridge': 262, 'around': 263, 'blue': 264, 'tell': 265, 'row': 266, 'how': 267, 'money': 268, 'merry': 269, 'stepped': 270, 'corporal': 271, 'always': 272, 'though': 273, 'near': 274, 'taken': 275, 'ones': 276, 'daughter': 277, 'forever': 278, 'loo': 279, 'shining': 280, 'plenty': 281, 'hes': 282, 'ship': 283, 'banks': 284, 'think': 285, 'very': 286, 'stand': 287, 'heres': 288, 'snow': 289, 'mountains': 290, 'molly': 291, 'wheel': 292, 'street': 293, 'erin': 294, 'side': 295, 'feet': 296, 'star': 297, 'look': 298, 'brave': 299, 'woman': 300, 'sons': 301, 'two': 302, 'says': 303, 'asked': 304, 'lanigans': 305, 'singing': 306, 'men': 307, 'toome': 308, 'stole': 309, 'god': 310, 'hill': 311, 'lonely': 312, 'lover': 313, 'tears': 314, 'fathers': 315, 'low': 316, 'voice': 317, 'quite': 318, 'able': 319, 'nice': 320, 'laid': 321, 'comrades': 322, 'wind': 323, 'another': 324, 'sit': 325, 'face': 326, 'band': 327, 'call': 328, 'colleen': 329, 'until': 330, 'hills': 331, 'mine': 332, 'above': 333, 'upon': 334, 'eer': 335, 'youve': 336, 'fly': 337, 'been': 338, 'late': 339, 'alive': 340, 'ballyjamesduff': 341, 'looked': 342, 'great': 343, 'why': 344, 'every': 345, 'proud': 346, 'found': 347, 'bragh': 348, 'such': 349, 'birds': 350, 'wedding': 351, 'welcome': 352, 'dancing': 353, 'da': 354, 'fell': 355, 'thinking': 356, 'roddy': 357, 'mccorley': 358, 'smiling': 359, 'mallow': 360, 'blooming': 361, 'thought': 362, 'peace': 363, 'soft': 364, 'pure': 365, 'harp': 366, 'dream': 367, 'alas': 368, 'yet': 369, 'clear': 370, 'art': 371, 'off': 372, 'hope': 373, 'fought': 374, 'mothers': 375, 'shore': 376, 'ago': 377, 'fol': 378, 'de': 379, 'house': 380, 'married': 381, 'bound': 382, 'danced': 383, 'devil': 384, 'dawning': 385, 'makes': 386, 'same': 387, 'sat': 388, 'any': 389, 'glass': 390, 'gay': 391, 'relations': 392, 'evening': 393, 'watched': 394, 'right': 395, 'fellows': 396, 'whiskey': 397, 'bonnie': 398, 'grows': 399, 'women': 400, 'flowers': 401, 'beauty': 402, 'cannot': 403, 'handsome': 404, 'happy': 405, 'gold': 406, 'rover': 407, 'none': 408, 'doneen': 409, 'summers': 410, 'people': 411, 'set': 412, 'paddy': 413, 'morn': 414, 'most': 415, 'easy': 416, 'struck': 417, 'beautiful': 418, 'those': 419, 'golden': 420, 'run': 421, 'pipes': 422, 'glen': 423, 'dying': 424, 'here': 425, 'wall': 426, 'across': 427, 'fire': 428, 'eileen': 429, 'longer': 430, 'cheeks': 431, 'valley': 432, 'both': 433, 'dew': 434, 'care': 435, 'bride': 436, 'nothing': 437, 'wont': 438, 'theyre': 439, 'colonel': 440, 'maiden': 441, 'shed': 442, 'til': 443, 'brown': 444, 'breast': 445, 'corn': 446, 'sinking': 447, 'began': 448, 'name': 449, 'cruel': 450, 'sound': 451, 'spancil': 452, 'county': 453, 'lies': 454, 'color': 455, 'thing': 456, 'decay': 457, 'sleep': 458, 'hours': 459, 'loving': 460, 'weary': 461, 'ringing': 462, 'please': 463, 'forget': 464, 'lie': 465, 'ran': 466, 'tore': 467, 'country': 468, 'fear': 469, 'fortune': 470, 'kissed': 471, 'alone': 472, 'ould': 473, 'cry': 474, 'dreams': 475, 'used': 476, 'horse': 477, 'break': 478, 'bells': 479, 'didnt': 480, 'weeks': 481, 'without': 482, 'raw': 483, 'nor': 484, 'twenty': 485, 'tune': 486, 'hed': 487, 'roving': 488, 'leaves': 489, 'cant': 490, 'death': 491, 'ten': 492, 'prison': 493, 'judge': 494, 'against': 495, 'lads': 496, 'shell': 497, 'fill': 498, 'valleys': 499, 'other': 500, 'pale': 501, 'joy': 502, 'wide': 503, 'bring': 504, 'ah': 505, 'cliffs': 506, 'city': 507, 'end': 508, 'turn': 509, 'sky': 510, 'born': 511, 'knew': 512, 'smiled': 513, 'rosie': 514, 'comes': 515, 'sayin': 516, 'lord': 517, 'dungannon': 518, 'blood': 519, 'air': 520, 'danny': 521, 'calling': 522, 'sunshine': 523, 'spring': 524, 'bid': 525, 'grow': 526, 'truth': 527, 'tear': 528, 'rings': 529, 'guns': 530, 'bay': 531, 'oflynn': 532, 'och': 533, 'stick': 534, 'rest': 535, 'four': 536, 'jewel': 537, 'tried': 538, 'grief': 539, 'answer': 540, 'kathleen': 541, 'fond': 542, 'eye': 543, 'goin': 544, 'pistols': 545, 'musha': 546, 'whack': 547, 'creole': 548, 'together': 549, 'room': 550, 'fall': 551, 'swore': 552, 'being': 553, 'step': 554, 'lark': 555, 'cailín': 556, 'deas': 557, 'crúite': 558, 'na': 559, 'mbó': 560, 'sir': 561, 'isle': 562, 'waiting': 563, 'magic': 564, 'skibbereen': 565, 'loud': 566, 'raise': 567, 'bent': 568, 'aged': 569, 'summer': 570, 'jenny': 571, 'excise': 572, 'rigadoo': 573, 'auld': 574, 'hearts': 575, 'nay': 576, 'stool': 577, 'farrell': 578, 'garden': 579, 'precious': 580, 'child': 581, 'slumber': 582, 'sleeping': 583, 'watch': 584, 'gently': 585, 'minstrel': 586, 'praise': 587, 'bell': 588, 'shaken': 589, 'immortal': 590, 'pray': 591, 'stay': 592, 'spoke': 593, 'cross': 594, 'brothers': 595, 'much': 596, 'past': 597, 'killarney': 598, 'sang': 599, 'tones': 600, 'ral': 601, 'wander': 602, 'cot': 603, 'feel': 604, 'yore': 605, 'answered': 606, 'divil': 607, 'middle': 608, 'bit': 609, 'led': 610, 'soldiers': 611, 'lily': 612, 'bed': 613, 'lassie': 614, 'clothes': 615, 'return': 616, 'broken': 617, 'derry': 618, 'sighed': 619, 'english': 620, 'tomorrow': 621, 'souls': 622, 'van': 623, 'diemans': 624, 'law': 625, 'neither': 626, 'winds': 627, 'rather': 628, 'doesnt': 629, 'rosy': 630, 'neatest': 631, 'hands': 632, 'whereon': 633, 'stands': 634, 'write': 635, 'thousand': 636, 'fare': 637, 'youd': 638, 'velvet': 639, 'neat': 640, 'landed': 641, 'health': 642, 'kellswater': 643, 'quiet': 644, 'stars': 645, 'beside': 646, 'warm': 647, 'sunday': 648, 'grey': 649, 'ocean': 650, 'sad': 651, 'spend': 652, 'kilkenny': 653, 'silver': 654, 'view': 655, 'west': 656, 'plain': 657, 'barrow': 658, 'broad': 659, 'narrow': 660, 'crying': 661, 'wonder': 662, 'save': 663, 'stop': 664, 'tender': 665, 'told': 666, 'lip': 667, 'dance': 668, 'foot': 669, 'kilrain': 670, 'saint': 671, 'visit': 672, 'mossy': 673, 'wexford': 674, 'irishmen': 675, 'shadow': 676, 'tho': 677, 'salley': 678, 'gardens': 679, 'foolish': 680, 'youth': 681, 'fade': 682, 'war': 683, 'believe': 684, 'which': 685, 'change': 686, 'entwine': 687, 'turns': 688, 'turned': 689, 'crown': 690, 'played': 691, 'captain': 692, 'blow': 693, 'children': 694, 'slainte': 695, 'gentle': 696, 'heavens': 697, 'bloom': 698, 'grand': 699, 'bush': 700, 'nest': 701, 'rich': 702, 'parting': 703, 'better': 704, 'window': 705, 'haste': 706, 'fresh': 707, 'stream': 708, 'rays': 709, 'ma': 710, 'ring': 711, 'lad': 712, 'athy': 713, 'drop': 714, 'hardly': 715, 'done': 716, 'arm': 717, 'leg': 718, 'beg': 719, 'drew': 720, 'bold': 721, 'drawn': 722, 'jail': 723, 'writin': 724, 'farewell': 725, 'tired': 726, 'lake': 727, 'want': 728, 'ringlets': 729, 'myself': 730, 'songs': 731, 'reel': 732, 'steps': 733, 'hearty': 734, 'fainted': 735, 'called': 736, 'under': 737, 'toe': 738, 'mairi': 739, 'fairest': 740, 'darlin': 741, 'bird': 742, 'memory': 743, 'lips': 744, 'sweetly': 745, 'morrow': 746, 'consent': 747, 'else': 748, 'sold': 749, 'stout': 750, 'pair': 751, 'drinking': 752, 'meself': 753, 'fray': 754, 'pike': 755, 'coat': 756, 'beneath': 757, 'rent': 758, 'part': 759, 'half': 760, 'head': 761, 'friend': 762, 'standing': 763, 'floor': 764, 'bare': 765, 'wed': 766, 'son': 767, 'pride': 768, 'vision': 769, 'sword': 770, 'after': 771, 'won': 772, 'farmers': 773, 'flower': 774, 'nut': 775, 'surely': 776, 'stood': 777, 'wandered': 778, 'athenry': 779, 'rising': 780, 'beating': 781, 'form': 782, 'dhu': 783, 'buy': 784, 'laughter': 785, 'wear': 786, 'raking': 787, 'rakes': 788, 'claret': 789, 'shure': 790, 'tralee': 791, 'slower': 792, 'lower': 793, 'deep': 794, 'wearin': 795, 'duram': 796, 'takes': 797, 'beware': 798, 'steal': 799, 'brings': 800, 'things': 801, 'joys': 802, 'bunch': 803, 'sailor': 804, 'chanced': 805, 'pass': 806, 'angels': 807, 'send': 808, 'drowsy': 809, 'keeping': 810, 'spirit': 811, 'stealing': 812, 'feeling': 813, 'roam': 814, 'presence': 815, 'heavenward': 816, 'dust': 817, 'dim': 818, 'journey': 819, 'waves': 820, 'frightened': 821, 'leaving': 822, 'struggle': 823, 'parents': 824, 'courage': 825, 'weeping': 826, 'pain': 827, 'mist': 828, 'felt': 829, 'roared': 830, 'making': 831, 'fever': 832, 'moment': 833, 'distance': 834, 'wailing': 835, 'oft': 836, 'held': 837, 'fast': 838, 'cabin': 839, 'honey': 840, 'diddle': 841, 'clearly': 842, 'open': 843, 'opened': 844, 'table': 845, 'wine': 846, 'lay': 847, 'shells': 848, 'sailed': 849, 'drown': 850, 'fetters': 851, 'chains': 852, 'wives': 853, 'sorrow': 854, 'thoughts': 855, 'cursed': 856, 'hell': 857, 'five': 858, 'buried': 859, 'lost': 860, 'endless': 861, 'slavery': 862, 'gun': 863, 'rain': 864, 'cares': 865, 'ghosts': 866, 'runaway': 867, 'twill': 868, 'month': 869, 'meadows': 870, 'prettiest': 871, 'winters': 872, 'satisfied': 873, 'few': 874, 'short': 875, 'lines': 876, 'shone': 877, 'shoulder': 878, 'belfast': 879, 'trade': 880, 'bad': 881, 'caused': 882, 'stray': 883, 'meaning': 884, 'damsel': 885, 'appear': 886, 'seven': 887, 'sentence': 888, 'jolly': 889, 'whenever': 890, 'wee': 891, 'wife': 892, 'lives': 893, 'martha': 894, 'courted': 895, 'bridgit': 896, 'omalley': 897, 'desolation': 898, 'thorn': 899, 'gaze': 900, 'stone': 901, 'approaching': 902, 'sets': 903, 'carrigfergus': 904, 'nights': 905, 'swim': 906, 'wings': 907, 'sober': 908, 'travel': 909, 'native': 910, 'places': 911, 'slopes': 912, 'hares': 913, 'lofty': 914, 'malone': 915, 'wheeled': 916, 'streets': 917, 'enough': 918, 'reilly': 919, 'tough': 920, 'whispers': 921, 'phil': 922, 'threw': 923, 'straight': 924, 'belles': 925, 'moor': 926, 'brand': 927, 'shapes': 928, 'work': 929, 'vow': 930, 'blarney': 931, 'paid': 932, 'bower': 933, 'remain': 934, 'charming': 935, 'storied': 936, 'chieftains': 937, 'slaughter': 938, 'bann': 939, 'boyne': 940, 'liffey': 941, 'gallant': 942, 'awake': 943, 'greet': 944, 'meadow': 945, 'sweeter': 946, 'dirty': 947, 'cats': 948, 'crossed': 949, 'field': 950, 'river': 951, 'full': 952, 'aroon': 953, 'sends': 954, 'woe': 955, 'chain': 956, 'main': 957, 'charms': 958, 'fondly': 959, 'fleet': 960, 'fairy': 961, 'thine': 962, 'known': 963, 'truly': 964, 'close': 965, 'story': 966, 'flag': 967, 'sweetest': 968, 'honor': 969, 'playing': 970, 'mauser': 971, 'music': 972, 'tom': 973, 'hurrah': 974, 'big': 975, 'lead': 976, 'south': 977, 'generation': 978, 'freedom': 979, 'agin': 980, 'creature': 981, 'dad': 982, 'venture': 983, 'word': 984, 'wonderful': 985, 'crazy': 986, 'lazy': 987, 'grave': 988, 'jest': 989, 'remark': 990, 'strangers': 991, 'strong': 992, 'shook': 993, 'walk': 994, 'north': 995, 'ours': 996, 'cease': 997, 'strife': 998, 'whats': 999, 'lilacs': 1000, 'prove': 1001, 'sweetheart': 1002, 'letters': 1003, 'sent': 1004, 'speak': 1005, 'brow': 1006, 'albert': 1007, 'mooney': 1008, 'fighting': 1009, 'fingers': 1010, 'toes': 1011, 'john': 1012, 'hurroo': 1013, 'drums': 1014, 'beguiled': 1015, 'carry': 1016, 'bone': 1017, 'havent': 1018, 'walkin': 1019, 'kilgary': 1020, 'pepper': 1021, 'countin': 1022, 'forth': 1023, 'deliver': 1024, 'daddy': 1025, 'em': 1026, 'deceive': 1027, 'between': 1028, 'even': 1029, 'prisoner': 1030, 'fists': 1031, 'knocked': 1032, 'carriages': 1033, 'rollin': 1034, 'juice': 1035, 'courtin': 1036, 'ponchartrain': 1037, 'does': 1038, 'stranger': 1039, 'marry': 1040, 'adieu': 1041, 'ask': 1042, 'tipped': 1043, 'arrived': 1044, 'ladies': 1045, 'potatoes': 1046, 'courting': 1047, 'miss': 1048, 'small': 1049, 'ned': 1050, 'ribbons': 1051, 'heel': 1052, 'bonny': 1053, 'pipe': 1054, 'thrush': 1055, 'sweethearts': 1056, 'unto': 1057, 'rise': 1058, 'softly': 1059, 'milking': 1060, 'rare': 1061, 'pity': 1062, 'treasure': 1063, 'noon': 1064, 'sailing': 1065, 'banish': 1066, 'riches': 1067, 'comfort': 1068, 'yonder': 1069, 'flows': 1070, 'fairer': 1071, 'lass': 1072, 'woods': 1073, 'strayed': 1074, 'locks': 1075, 'breaking': 1076, 'june': 1077, 'started': 1078, 'hearted': 1079, 'beer': 1080, 'daylight': 1081, 'among': 1082, 'bundle': 1083, 'connaught': 1084, 'quay': 1085, 'erins': 1086, 'galway': 1087, 'fearless': 1088, 'bravely': 1089, 'marches': 1090, 'fate': 1091, 'neck': 1092, 'trod': 1093, 'marched': 1094, 'antrim': 1095, 'sash': 1096, 'flashed': 1097, 'hath': 1098, 'foemans': 1099, 'fight': 1100, 'heavy': 1101, 'bore': 1102, 'mans': 1103, 'counter': 1104, 'dozen': 1105, 'gallon': 1106, 'bottles': 1107, 'diamond': 1108, 'resemble': 1109, 'tiny': 1110, 'friendly': 1111, 'weather': 1112, 'inside': 1113, 'remember': 1114, 'someone': 1115, 'hat': 1116, 'body': 1117, 'dancers': 1118, 'hanging': 1119, 'empty': 1120, 'shoes': 1121, 'broke': 1122, 'december': 1123, 'move': 1124, 'reason': 1125, 'roof': 1126, 'naught': 1127, 'tower': 1128, 'power': 1129, 'king': 1130, 'dreaming': 1131, 'crew': 1132, 'whos': 1133, 'mccann': 1134, 'smoke': 1135, 'notes': 1136, 'yeoman': 1137, 'cavalry': 1138, 'guard': 1139, 'forced': 1140, 'brother': 1141, 'cousin': 1142, 'blame': 1143, 'croppy': 1144, 'dressed': 1145, 'trees': 1146, 'wore': 1147, 'words': 1148, 'swiftly': 1149, 'dawn': 1150, 'lovd': 1151, 'voices': 1152, 'moaning': 1153, 'dark': 1154, 'gather': 1155, 'tay': 1156, 'swinging': 1157, 'drinkin': 1158, 'sitting': 1159, 'stile': 1160, 'springing': 1161, 'yours': 1162, 'kept': 1163, 'aisey': 1164, 'rub': 1165, 'dub': 1166, 'dow': 1167, 'shelah': 1168, 'fairly': 1169, 'beggarman': 1170, 'begging': 1171, 'slept': 1172, 'holes': 1173, 'coming': 1174, 'thru': 1175, 'boo': 1176, 'lady': 1177, 'kerry': 1178, 'pipers': 1179, 'laugh': 1180, 'beaming': 1181, 'guineas': 1182, 'least': 1183, 'diggin': 1184, 'mourne': 1185, 'spending': 1186, 'mellow': 1187, 'plying': 1188, 'slowly': 1189, 'mooncoin': 1190, 'flow': 1191, 'sounds': 1192, 'shine': 1193, 'cool': 1194, 'crystal': 1195, 'fountain': 1196, 'moonlight': 1197, 'grandmother': 1198, 'crooning': 1199, 'merrily': 1200, 'spins': 1201, 'lightly': 1202, 'moving': 1203, 'lattice': 1204, 'grove': 1205, 'swings': 1206, 'finger': 1207, 'shamrock': 1208, 'pocket': 1209, 'springtime': 1210, 'gilgarra': 1211, 'rapier': 1212, 'ringum': 1213, 'mornin': 1214, 'heather': 1215, 'build': 1216, 'maidens': 1217, 'prime': 1218, 'nlyme': 1219, 'flavours': 1220, 'lusty': 1221, 'reminded': 1222, 'attend': 1223, 'guardian': 1224, 'creeping': 1225, 'dale': 1226, 'vigil': 1227, 'visions': 1228, 'revealing': 1229, 'breathes': 1230, 'holy': 1231, 'strains': 1232, 'hover': 1233, 'hark': 1234, 'solemn': 1235, 'winging': 1236, 'earthly': 1237, 'shalt': 1238, 'awaken': 1239, 'destiny': 1240, 'emigrants': 1241, 'amid': 1242, 'longing': 1243, 'parted': 1244, 'townland': 1245, 'vessel': 1246, 'crowded': 1247, 'disquieted': 1248, 'folk': 1249, 'escape': 1250, 'hardship': 1251, 'sustaining': 1252, 'glimpse': 1253, 'faded': 1254, 'strangely': 1255, 'seas': 1256, 'anger': 1257, 'desperate': 1258, 'plight': 1259, 'worsened': 1260, 'delirium': 1261, 'possessed': 1262, 'clouded': 1263, 'prayers': 1264, 'begged': 1265, 'forgiveness': 1266, 'seeking': 1267, 'distant': 1268, 'mither': 1269, 'simple': 1270, 'ditty': 1271, 'ld': 1272, 'li': 1273, 'hush': 1274, 'lullaby': 1275, 'huggin': 1276, 'hummin': 1277, 'rock': 1278, 'asleep': 1279, 'outside': 1280, 'modestly': 1281, 'ry': 1282, 'ay': 1283, 'di': 1284, 're': 1285, 'dai': 1286, 'rie': 1287, 'shc': 1288, 'bridle': 1289, 'stable': 1290, 'oats': 1291, 'eat': 1292, 'soldier': 1293, 'aisy': 1294, 'arose': 1295, 'christmas': 1296, '1803': 1297, 'australia': 1298, 'marks': 1299, 'carried': 1300, 'rusty': 1301, 'iron': 1302, 'wains': 1303, 'mainsails': 1304, 'unfurled': 1305, 'curses': 1306, 'hurled': 1307, 'swell': 1308, 'moth': 1309, 'firelights': 1310, 'horses': 1311, 'rode': 1312, 'taking': 1313, 'hades': 1314, 'twilight': 1315, 'forty': 1316, 'slime': 1317, 'climate': 1318, 'bravery': 1319, 'ended': 1320, 'bond': 1321, 'rebel': 1322, 'iii': 1323, 'violin': 1324, 'clay': 1325, 'sooner': 1326, 'sport': 1327, 'colour': 1328, 'knows': 1329, 'earth': 1330, 'serve': 1331, 'clyde': 1332, 'mourn': 1333, 'weep': 1334, 'suffer': 1335, 'diamonds': 1336, 'queen': 1337, 'hung': 1338, 'tied': 1339, 'apprenticed': 1340, 'happiness': 1341, 'misfortune': 1342, 'follow': 1343, 'strolling': 1344, 'selling': 1345, 'bar': 1346, 'customer': 1347, 'slipped': 1348, 'luck': 1349, 'jury': 1350, 'trial': 1351, 'case': 1352, 'warning': 1353, 'liquor': 1354, 'porter': 1355, 'pleasures': 1356, 'fishing': 1357, 'farming': 1358, 'glens': 1359, 'softest': 1360, 'dripping': 1361, 'snare': 1362, 'lose': 1363, 'court': 1364, 'primrose': 1365, 'bee': 1366, 'hopeless': 1367, 'wonders': 1368, 'admiration': 1369, 'haunt': 1370, 'wherever': 1371, 'sands': 1372, 'purer': 1373, 'within': 1374, 'grieve': 1375, 'drumslieve': 1376, 'ballygrant': 1377, 'deepest': 1378, 'boatsman': 1379, 'ferry': 1380, 'childhood': 1381, 'reflections': 1382, 'boyhood': 1383, 'melting': 1384, 'roaming': 1385, 'reported': 1386, 'marble': 1387, 'stones': 1388, 'ink': 1389, 'support': 1390, 'drunk': 1391, 'seldom': 1392, 'sick': 1393, 'numbered': 1394, 'foam': 1395, 'compare': 1396, 'sights': 1397, 'coast': 1398, 'clare': 1399, 'kilkee': 1400, 'kilrush': 1401, 'watching': 1402, 'pheasants': 1403, 'homes': 1404, 'streams': 1405, 'dublins': 1406, 'cockles': 1407, 'mussels': 1408, 'fish': 1409, 'monger': 1410, 'ghost': 1411, 'wheels': 1412, 'eden': 1413, 'vanished': 1414, 'finea': 1415, 'halfway': 1416, 'cootehill': 1417, 'gruff': 1418, 'whispering': 1419, 'crow': 1420, 'newborn': 1421, 'babies': 1422, 'huff': 1423, 'start': 1424, 'sorrowful': 1425, 'squall': 1426, 'babys': 1427, 'toil': 1428, 'worn': 1429, 'fore': 1430, 'flute': 1431, 'yer': 1432, 'boot': 1433, 'magee': 1434, 'scruff': 1435, 'slanderin': 1436, 'marchin': 1437, 'assisted': 1438, 'drain': 1439, 'dudeen': 1440, 'puff': 1441, 'whisperings': 1442, 'barrin': 1443, 'chocolate': 1444, 'feegee': 1445, 'sort': 1446, 'moonshiny': 1447, 'stuff': 1448, 'addle': 1449, 'brain': 1450, 'ringin': 1451, 'glamour': 1452, 'gas': 1453, 'guff': 1454, 'whisper': 1455, 'oil': 1456, 'remarkable': 1457, 'policeman': 1458, 'bluff': 1459, 'maintain': 1460, 'guril': 1461, 'sic': 1462, 'passage': 1463, 'rough': 1464, 'borne': 1465, 'breeze': 1466, 'boundless': 1467, 'stupendous': 1468, 'roll': 1469, 'thundering': 1470, 'motion': 1471, 'mermaids': 1472, 'fierce': 1473, 'tempest': 1474, 'gathers': 1475, 'oneill': 1476, 'odonnell': 1477, 'lucan': 1478, 'oconnell': 1479, 'brian': 1480, 'drove': 1481, 'danes': 1482, 'patrick': 1483, 'vermin': 1484, 'whose': 1485, 'benburb': 1486, 'blackwater': 1487, 'owen': 1488, 'roe': 1489, 'munroe': 1490, 'lambs': 1491, 'skip': 1492, 'views': 1493, 'enchanting': 1494, 'rostrevor': 1495, 'groves': 1496, 'lakes': 1497, 'ride': 1498, 'tide': 1499, 'majestic': 1500, 'shannon': 1501, 'sail': 1502, 'loch': 1503, 'neagh': 1504, 'ross': 1505, 'gorey': 1506, 'saxon': 1507, 'tory': 1508, 'soil': 1509, 'sanctified': 1510, 'enemies': 1511, 'links': 1512, 'encumbered': 1513, 'resound': 1514, 'hosannahs': 1515, 'bide': 1516, 'hushed': 1517, 'lying': 1518, 'kneel': 1519, 'ave': 1520, 'tread': 1521, 'fail': 1522, 'simply': 1523, 'gasworks': 1524, 'croft': 1525, 'dreamed': 1526, 'canal': 1527, 'factory': 1528, 'clouds': 1529, 'drifting': 1530, 'prowling': 1531, 'beat': 1532, 'springs': 1533, 'siren': 1534, 'docks': 1535, 'train': 1536, 'smelled': 1537, 'smokey': 1538, 'sharp': 1539, 'axe': 1540, 'steel': 1541, 'tempered': 1542, 'chop': 1543, 't': 1544, 'agree': 1545, 'leaning': 1546, 'weirs': 1547, 'ray': 1548, 'glow': 1549, 'changeless': 1550, 'constant': 1551, 'bounding': 1552, 'castles': 1553, 'sacked': 1554, 'scattered': 1555, 'fixed': 1556, 'endearing': 1557, 'gifts': 1558, 'fading': 1559, 'wouldst': 1560, 'adored': 1561, 'loveliness': 1562, 'ruin': 1563, 'itself': 1564, 'verdantly': 1565, 'unprofaned': 1566, 'fervor': 1567, 'faith': 1568, 'forgets': 1569, 'sunflower': 1570, 'rag': 1571, 'games': 1572, 'hold': 1573, 'defend': 1574, 'veteran': 1575, 'volunteers': 1576, 'pat': 1577, 'pearse': 1578, 'clark': 1579, 'macdonagh': 1580, 'macdiarmada': 1581, 'mcbryde': 1582, 'james': 1583, 'connolly': 1584, 'placed': 1585, 'machine': 1586, 'ranting': 1587, 'hour': 1588, 'bullet': 1589, 'stuck': 1590, 'craw': 1591, 'poisoning': 1592, 'ceannt': 1593, 'lions': 1594, 'union': 1595, 'poured': 1596, 'dismay': 1597, 'horror': 1598, 'englishmen': 1599, 'khaki': 1600, 'renown': 1601, 'fame': 1602, 'forefathers': 1603, 'blaze': 1604, 'priests': 1605, 'offer': 1606, 'charmin': 1607, 'variety': 1608, 'renownd': 1609, 'learnin': 1610, 'piety': 1611, 'advance': 1612, 'widout': 1613, 'impropriety': 1614, 'flowr': 1615, 'cho': 1616, 'powrfulest': 1617, 'preacher': 1618, 'tenderest': 1619, 'teacher': 1620, 'kindliest': 1621, 'donegal': 1622, 'talk': 1623, 'provost': 1624, 'trinity': 1625, 'famous': 1626, 'greek': 1627, 'latinity': 1628, 'divils': 1629, 'divinity': 1630, 'd': 1631, 'likes': 1632, 'logic': 1633, 'mythology': 1634, 'thayology': 1635, 'conchology': 1636, 'sinners': 1637, 'wishful': 1638, 'childer': 1639, 'avick': 1640, 'gad': 1641, 'flock': 1642, 'grandest': 1643, 'control': 1644, 'checking': 1645, 'coaxin': 1646, 'onaisy': 1647, 'lifting': 1648, 'avoidin': 1649, 'frivolity': 1650, 'seasons': 1651, 'innocent': 1652, 'jollity': 1653, 'playboy': 1654, 'claim': 1655, 'equality': 1656, 'comicality': 1657, 'bishop': 1658, 'lave': 1659, 'gaiety': 1660, 'laity': 1661, 'clergy': 1662, 'jewels': 1663, 'plundering': 1664, 'pillage': 1665, 'starved': 1666, 'cries': 1667, 'thems': 1668, 'bondage': 1669, 'fourth': 1670, 'tabhair': 1671, 'dom': 1672, 'lámh': 1673, 'harmony': 1674, 'east': 1675, 'destroy': 1676, 'command': 1677, 'gesture': 1678, 'troubles': 1679, 'weak': 1680, 'peoples': 1681, 'creeds': 1682, 'lets': 1683, 'needs': 1684, 'passion': 1685, 'fashion': 1686, 'guide': 1687, 'share': 1688, 'sparkling': 1689, 'meeting': 1690, 'iull': 1691, 'contented': 1692, 'ache': 1693, 'painful': 1694, 'wrote': 1695, 'twisted': 1696, 'twined': 1697, 'cheek': 1698, 'bedim': 1699, 'holds': 1700, 'smiles': 1701, 'scarcely': 1702, 'darkning': 1703, 'beyond': 1704, 'yearn': 1705, 'laughs': 1706, 'humble': 1707, 'brightest': 1708, 'gleam': 1709, 'forgot': 1710, 'pulled': 1711, 'comb': 1712, 'counting': 1713, 'knock': 1714, 'murray': 1715, 'fellow': 1716, 'hail': 1717, 'tumblin': 1718, 'apple': 1719, 'pie': 1720, 'gets': 1721, 'doleful': 1722, 'enemy': 1723, 'nearly': 1724, 'slew': 1725, 'queer': 1726, 'mild': 1727, 'legs': 1728, 'indeed': 1729, 'island': 1730, 'sulloon': 1731, 'flesh': 1732, 'yere': 1733, 'armless': 1734, 'boneless': 1735, 'chickenless': 1736, 'egg': 1737, 'yell': 1738, 'bowl': 1739, 'rolling': 1740, 'swearing': 1741, 'rattled': 1742, 'saber': 1743, 'deceiver': 1744, 'rig': 1745, 'um': 1746, 'du': 1747, 'rum': 1748, 'jar': 1749, 'shinin': 1750, 'coins': 1751, 'promised': 1752, 'vowed': 1753, 'devils': 1754, 'awakened': 1755, 'six': 1756, 'guards': 1757, 'numbers': 1758, 'odd': 1759, 'flew': 1760, 'mistaken': 1761, 'mollys': 1762, 'robbing': 1763, 'sentry': 1764, 'sligo': 1765, 'fishin': 1766, 'bowlin': 1767, 'others': 1768, 'railroad': 1769, 'ties': 1770, 'crossings': 1771, 'swamps': 1772, 'elevations': 1773, 'resolved': 1774, 'sunset': 1775, 'higher': 1776, 'win': 1777, 'allegators': 1778, 'wood': 1779, 'treated': 1780, 'shoulders': 1781, 'paint': 1782, 'picture': 1783, 'vain': 1784, 'returned': 1785, 'cottage': 1786, 'sociable': 1787, 'foaming': 1788, 'n': 1789, 'jeremy': 1790, 'lanigan': 1791, 'battered': 1792, 'hadnt': 1793, 'pound': 1794, 'farm': 1795, 'acres': 1796, 'party': 1797, 'listen': 1798, 'glisten': 1799, 'rows': 1800, 'ructions': 1801, 'invitation': 1802, 'minute': 1803, 'bees': 1804, 'cask': 1805, 'judy': 1806, 'odaly': 1807, 'milliner': 1808, 'wink': 1809, 'peggy': 1810, 'mcgilligan': 1811, 'lashings': 1812, 'punch': 1813, 'cakes': 1814, 'bacon': 1815, 'tea': 1816, 'nolans': 1817, 'dolans': 1818, 'ogradys': 1819, 'sounded': 1820, 'taras': 1821, 'hall': 1822, 'nelly': 1823, 'gray': 1824, 'rat': 1825, 'catchers': 1826, 'doing': 1827, 'kinds': 1828, 'nonsensical': 1829, 'polkas': 1830, 'whirligig': 1831, 'julia': 1832, 'banished': 1833, 'nonsense': 1834, 'twist': 1835, 'jig': 1836, 'mavrone': 1837, 'mad': 1838, 'ceiling': 1839, 'brooks': 1840, 'academy': 1841, 'learning': 1842, 'learn': 1843, 'couples': 1844, 'groups': 1845, 'accident': 1846, 'happened': 1847, 'terrance': 1848, 'mccarthy': 1849, 'finnertys': 1850, 'hoops': 1851, 'cried': 1852, 'meelia': 1853, 'murther': 1854, 'gathered': 1855, 'carmody': 1856, 'further': 1857, 'satisfaction': 1858, 'midst': 1859, 'kerrigan': 1860, 'declared': 1861, 'painted': 1862, 'suppose': 1863, 'morgan': 1864, 'powerful': 1865, 'stretched': 1866, 'smashed': 1867, 'chaneys': 1868, 'runctions': 1869, 'lick': 1870, 'phelim': 1871, 'mchugh': 1872, 'replied': 1873, 'introduction': 1874, 'kicked': 1875, 'terrible': 1876, 'hullabaloo': 1877, 'piper': 1878, 'strangled': 1879, 'squeezed': 1880, 'bellows': 1881, 'chanters': 1882, 'entangled': 1883, 'gaily': 1884, 'mairis': 1885, 'hillways': 1886, 'myrtle': 1887, 'bracken': 1888, 'sheilings': 1889, 'sake': 1890, 'rowans': 1891, 'herring': 1892, 'meal': 1893, 'peat': 1894, 'creel': 1895, 'bairns': 1896, 'weel': 1897, 'toast': 1898, 'soar': 1899, 'blackbird': 1900, 'note': 1901, 'linnet': 1902, 'lure': 1903, 'cozy': 1904, 'catch': 1905, 'company': 1906, 'harm': 1907, 'wit': 1908, 'recall': 1909, 'leisure': 1910, 'awhile': 1911, 'sorely': 1912, 'ruby': 1913, 'enthralled': 1914, 'sorry': 1915, 'theyd': 1916, 'falls': 1917, 'lot': 1918, 'tuned': 1919, 'bough': 1920, 'cow': 1921, 'chanting': 1922, 'melodious': 1923, 'scarce': 1924, 'soothed': 1925, 'solace': 1926, 'courtesy': 1927, 'salute': 1928, 'amiable': 1929, 'captive': 1930, 'slave': 1931, 'future': 1932, 'banter': 1933, 'enamour': 1934, 'indies': 1935, 'afford': 1936, 'transparently': 1937, 'flame': 1938, 'add': 1939, 'fuel': 1940, 'grant': 1941, 'desire': 1942, 'expire': 1943, 'wealth': 1944, 'damer': 1945, 'african': 1946, 'devonshire': 1947, 'lamp': 1948, 'alladin': 1949, 'genie': 1950, 'also': 1951, 'withdraw': 1952, 'tease': 1953, 'single': 1954, 'airy': 1955, 'embarrass': 1956, 'besides': 1957, 'almanack': 1958, 'useless': 1959, 'date': 1960, 'ware': 1961, 'rate': 1962, 'fragrance': 1963, 'loses': 1964, 'consumed': 1965, 'october': 1966, 'knowing': 1967, 'steer': 1968, 'blast': 1969, 'danger': 1970, 'farthing': 1971, 'affection': 1972, 'enjoy': 1973, 'choose': 1974, 'killarneys': 1975, 'sister': 1976, 'pains': 1977, 'loss': 1978, 'tuam': 1979, 'saluted': 1980, 'drank': 1981, 'pint': 1982, 'smother': 1983, 'reap': 1984, 'cut': 1985, 'goblins': 1986, 'bought': 1987, 'brogues': 1988, 'rattling': 1989, 'bogs': 1990, 'frightning': 1991, 'dogs': 1992, 'hunt': 1993, 'hare': 1994, 'follol': 1995, 'rah': 1996, 'mullingar': 1997, 'rested': 1998, 'limbs': 1999, 'blithe': 2000, 'heartfrom': 2001, 'paddys': 2002, 'cure': 2003, 'lassies': 2004, 'laughing': 2005, 'curious': 2006, 'style': 2007, 'twould': 2008, 'bubblin': 2009, 'hired': 2010, 'wages': 2011, 'required': 2012, 'almost': 2013, 'deprived': 2014, 'stroll': 2015, 'quality': 2016, 'locality': 2017, 'something': 2018, 'wobblin': 2019, 'enquiring': 2020, 'rogue': 2021, 'brogue': 2022, 'wasnt': 2023, 'vogue': 2024, 'spirits': 2025, 'falling': 2026, 'jumped': 2027, 'aboard': 2028, 'pigs': 2029, 'rigs': 2030, 'jigs': 2031, 'bubbling': 2032, 'holyhead': 2033, 'wished': 2034, 'instead': 2035, 'bouys': 2036, 'liverpool': 2037, 'safely': 2038, 'fool': 2039, 'boil': 2040, 'temper': 2041, 'losing': 2042, 'abusing': 2043, 'shillelagh': 2044, 'nigh': 2045, 'hobble': 2046, 'load': 2047, 'hurray': 2048, 'joined': 2049, 'affray': 2050, 'quitely': 2051, 'cleared': 2052, 'host': 2053, 'march': 2054, 'faces': 2055, 'farmstead': 2056, 'fishers': 2057, 'ban': 2058, 'vengeance': 2059, 'hapless': 2060, 'about': 2061, 'hemp': 2062, 'rope': 2063, 'clung': 2064, 'grim': 2065, 'array': 2066, 'earnest': 2067, 'stalwart': 2068, 'stainless': 2069, 'banner': 2070, 'marching': 2071, 'torn': 2072, 'furious': 2073, 'odds': 2074, 'keen': 2075, 'toomebridge': 2076, 'treads': 2077, 'upwards': 2078, 'traveled': 2079, 'quarters': 2080, 'below': 2081, 'hogshead': 2082, 'stack': 2083, 'stagger': 2084, 'dig': 2085, 'hole': 2086, 'couple': 2087, 'scratch': 2088, 'consolation': 2089, 'tyrant': 2090, 'remorseless': 2091, 'foe': 2092, 'lift': 2093, 'stranded': 2094, 'prince': 2095, 'edward': 2096, 'coffee': 2097, 'trace': 2098, 'fiddlin': 2099, 'dime': 2100, 'shy': 2101, 'hello': 2102, 'wintry': 2103, 'yellow': 2104, 'somewhere': 2105, 'written': 2106, 'begin': 2107, 'tap': 2108, 'caught': 2109, 'leap': 2110, 'clumsy': 2111, 'graceful': 2112, 'fiddlers': 2113, 'everywhere': 2114, 'boots': 2115, 'laughtcr': 2116, 'suits': 2117, 'easter': 2118, 'gowns': 2119, 'sailors': 2120, 'pianos': 2121, 'setting': 2122, 'someones': 2123, 'hats': 2124, 'rack': 2125, 'chair': 2126, 'wooden': 2127, 'feels': 2128, 'touch': 2129, 'awaitin': 2130, 'thc': 2131, 'fiddles': 2132, 'closet': 2133, 'strings': 2134, 'tbe': 2135, 'covers': 2136, 'buttoned': 2137, 'sometimes': 2138, 'melody': 2139, 'passes': 2140, 'slight': 2141, 'lack': 2142, 'moved': 2143, 'homeward': 2144, 'swan': 2145, 'moves': 2146, 'goods': 2147, 'gear': 2148, 'din': 2149, 'rude': 2150, 'wherein': 2151, 'dwell': 2152, 'abandon': 2153, 'energy': 2154, 'blight': 2155, 'praties': 2156, 'sheep': 2157, 'cattle': 2158, 'taxes': 2159, 'unpaid': 2160, 'redeem': 2161, 'bleak': 2162, 'landlord': 2163, 'sheriff': 2164, 'spleen': 2165, 'heaved': 2166, 'sigh': 2167, 'bade': 2168, 'goodbye': 2169, 'stony': 2170, 'anguish': 2171, 'seeing': 2172, 'feeble': 2173, 'frame': 2174, 'wrapped': 2175, 'c�ta': 2176, 'm�r': 2177, 'unseen': 2178, 'stern': 2179, 'rally': 2180, 'cheer': 2181, 'revenge': 2182, 'waking': 2183, 'wisdom': 2184, 'dwelling': 2185, 'battleshield': 2186, 'dignity': 2187, 'shelter': 2188, 'heed': 2189, 'inheritance': 2190, 'heavem': 2191, 'heaven': 2192, 'victory': 2193, 'reach': 2194, 'whatever': 2195, 'befall': 2196, 'ruler': 2197, 'pleasant': 2198, 'rambling': 2199, 'board': 2200, 'followed': 2201, 'shortly': 2202, 'anchor': 2203, '23rd': 2204, 'lrelands': 2205, 'daughters': 2206, 'crowds': 2207, 'assembled': 2208, 'fulfill': 2209, 'jovial': 2210, 'conversations': 2211, 'neighbors': 2212, 'turning': 2213, 'tailor': 2214, 'quigley': 2215, 'bould': 2216, 'britches': 2217, 'lived': 2218, 'flying': 2219, 'dove': 2220, 'hiii': 2221, 'dreamt': 2222, 'joking': 2223, 'manys': 2224, 'cock': 2225, 'shrill': 2226, 'awoke': 2227, 'california': 2228, 'miles': 2229, 'banbridge': 2230, 'july': 2231, 'boreen': 2232, 'sheen': 2233, 'coaxing': 2234, 'elf': 2235, 'shake': 2236, 'bantry': 2237, 'onward': 2238, 'sped': 2239, 'gazed': 2240, 'passerby': 2241, 'gem': 2242, 'irelands': 2243, 'travelled': 2244, 'hit': 2245, 'career': 2246, 'square': 2247, 'surrendered': 2248, 'tenant': 2249, 'shawl': 2250, 'gown': 2251, 'crossroads': 2252, 'dress': 2253, 'try': 2254, 'sheeps': 2255, 'deludhering': 2256, 'yoke': 2257, 'rust': 2258, 'plow': 2259, 'fireside': 2260, 'sits': 2261, 'whistle': 2262, 'changing': 2263, 'fright': 2264, 'downfall': 2265, 'cornwall': 2266, 'parlour': 2267, 'passing': 2268, 'william': 2269, 'betray': 2270, 'guinea': 2271, 'walking': 2272, 'mounted': 2273, 'platform': 2274, 'deny': 2275, 'walked': 2276, 'margin': 2277, 'lough': 2278, 'leane': 2279, 'bloomed': 2280, 'whom': 2281, 'cap': 2282, 'cloak': 2283, 'glossy': 2284, 'pail': 2285, 'palm': 2286, 'venus': 2287, 'bank': 2288, 'travelians': 2289, 'babes': 2290, 'freebirds': 2291, 'grew': 2292, 'matters': 2293, 'famine': 2294, 'rebelled': 2295, 'windswept': 2296, 'harbour': 2297, 'botany': 2298, 'whilst': 2299, 'wan': 2300, 'cloud': 2301, 'shannons': 2302, 'returnd': 2303, 'doubts': 2304, 'fears': 2305, 'aching': 2306, 'seemd': 2307, 'mingling': 2308, 'flood': 2309, 'path': 2310, 'wrath': 2311, 'lamenting': 2312, 'sudden': 2313, 'kissd': 2314, 'showrs': 2315, 'flowing': 2316, 'laughd': 2317, 'beam': 2318, 'soared': 2319, 'aloft': 2320, 'phantom': 2321, 'outspread': 2322, 'throbbing': 2323, 'hid': 2324, 'treasures': 2325, 'pots': 2326, 'tin': 2327, 'cans': 2328, 'mash': 2329, 'bran': 2330, 'barney': 2331, 'peeled': 2332, 'searching': 2333, 'connemara': 2334, 'butcher': 2335, 'quart': 2336, 'bottle': 2337, 'help': 2338, 'gate': 2339, 'glory': 2340, 'lane': 2341, 'village': 2342, 'church': 2343, 'spire': 2344, 'graveyard': 2345, 'baby': 2346, 'blessing': 2347, 'hoping': 2348, 'trust': 2349, 'strength': 2350, 'thank': 2351, 'bidding': 2352, 'bread': 2353, 'shines': 2354, 'fifty': 2355, 'often': 2356, 'shut': 2357, 'frisky': 2358, 'pig': 2359, 'whisky': 2360, 'uncle': 2361, 'enlisted': 2362, 'trudged': 2363, 'bosom': 2364, 'daisy': 2365, 'drubbing': 2366, 'shirts': 2367, 'battle': 2368, 'blows': 2369, 'pate': 2370, 'bothered': 2371, 'rarely': 2372, 'dropped': 2373, 'honest': 2374, 'thinks': 2375, 'eight': 2376, 'score': 2377, 'basin': 2378, 'zoo': 2379, 'everybody': 2380, 'calls': 2381, 'trades': 2382, 'dinner': 2383, 'slip': 2384, 'corner': 2385, 'barn': 2386, 'currabawn': 2387, 'shocking': 2388, 'wet': 2389, 'raindrops': 2390, 'rats': 2391, 'peek': 2392, 'waken': 2393, 'spotted': 2394, 'apron': 2395, 'calico': 2396, 'blouse': 2397, 'frighten': 2398, 'afraid': 2399, 'flaxen': 2400, 'haired': 2401, 'rags': 2402, 'tags': 2403, 'leggins': 2404, 'collar': 2405, 'tie': 2406, 'goggles': 2407, 'fashioned': 2408, 'bag': 2409, 'bulging': 2410, 'sack': 2411, 'peeping': 2412, 'skin': 2413, 'rink': 2414, 'doodle': 2415, 'getting': 2416, 'raked': 2417, 'gladness': 2418, 'tuning': 2419, 'fills': 2420, 'eily': 2421, 'prouder': 2422, 'thady': 2423, 'boldly': 2424, 'lasses': 2425, 'fled': 2426, 'silent': 2427, 'glad': 2428, 'echo': 2429, 'companions': 2430, 'soars': 2431, 'enchanted': 2432, 'granted': 2433, 'adoration': 2434, 'gives': 2435, 'joyous': 2436, 'elation': 2437, 'covered': 2438, 'winter': 2439, 'riding': 2440, 'cherry': 2441, 'coal': 2442, 'falter': 2443, 'bowed': 2444, 'bonnet': 2445, 'courteous': 2446, 'looks': 2447, 'engaging': 2448, 'sell': 2449, 'purse': 2450, 'yearly': 2451, 'need': 2452, 'market': 2453, 'gain': 2454, 'dearly': 2455, 'tarry': 2456, 'although': 2457, 'parlay': 2458, 'ranks': 2459, 'girded': 2460, 'slung': 2461, 'warrior': 2462, 'bard': 2463, 'betrays': 2464, 'rights': 2465, 'faithful': 2466, 'chords': 2467, 'asunder': 2468, 'sully': 2469, 'bravry': 2470, 'londons': 2471, 'sight': 2472, 'workin': 2473, 'sow': 2474, 'wheat': 2475, 'gangs': 2476, 'sweep': 2477, 'expressed': 2478, 'london': 2479, 'top': 2480, 'dresses': 2481, 'bath': 2482, 'startin': 2483, 'fashions': 2484, 'mccree': 2485, 'nature': 2486, 'designed': 2487, 'complexions': 2488, 'cream': 2489, 'regard': 2490, 'sip': 2491, 'colors': 2492, 'wait': 2493, 'waitin': 2494, 'sweeps': 2495, 'beauing': 2496, 'belling': 2497, 'windows': 2498, 'cursing': 2499, 'faster': 2500, 'waiters': 2501, 'bailiffs': 2502, 'duns': 2503, 'bacchus': 2504, 'begotten': 2505, 'politicians': 2506, 'funds': 2507, 'dadda': 2508, 'living': 2509, 'drives': 2510, 'having': 2511, 'racking': 2512, 'tenants': 2513, 'stewards': 2514, 'teasing': 2515, 'raising': 2516, 'wishing': 2517, 'sunny': 2518, 'doves': 2519, 'coo': 2520, 'neath': 2521, 'sunbeam': 2522, 'robin': 2523, 'waters': 2524, 'larks': 2525, 'join': 2526, 'breaks': 2527, 'oftimes': 2528, 'lilies': 2529, 'declining': 2530, 'vale': 2531, 'shades': 2532, 'mantle': 2533, 'spreading': 2534, 'listening': 2535, 'shedding': 2536, 'beginning': 2537, 'spinning': 2538, 'blind': 2539, 'drowsily': 2540, 'knitting': 2541, 'cheerily': 2542, 'noiselessly': 2543, 'whirring': 2544, 'foots': 2545, 'stirring': 2546, 'sprightly': 2547, 'chara': 2548, 'tapping': 2549, 'ivy': 2550, 'flapping': 2551, 'somebody': 2552, 'sighing': 2553, 'autumn': 2554, 'noise': 2555, 'chirping': 2556, 'holly': 2557, 'shoving': 2558, 'wrong': 2559, 'coolin': 2560, 'casement': 2561, 'rove': 2562, 'moons': 2563, 'brightly': 2564, 'shakes': 2565, 'lays': 2566, 'longs': 2567, 'lingers': 2568, 'glance': 2569, 'puts': 2570, 'lazily': 2571, 'easily': 2572, 'lowly': 2573, 'reels': 2574, 'noiseless': 2575, 'leaps': 2576, 'ere': 2577, 'lovers': 2578, 'roved': 2579, 'verdant': 2580, 'braes': 2581, 'skreen': 2582, 'countrie': 2583, 'foreign': 2584, 'strand': 2585, 'dewy': 2586, 'climb': 2587, 'rob': 2588, 'boat': 2589, 'sails': 2590, 'loaded': 2591, 'sink': 2592, 'leaned': 2593, 'oak': 2594, 'trusty': 2595, 'false': 2596, 'reached': 2597, 'pricked': 2598, 'waxes': 2599, 'fades': 2600, 'wholl': 2601, 'cockle': 2602, 'gloom': 2603, 'news': 2604, 'forbid': 2605, 'patricks': 2606, 'napper': 2607, 'tandy': 2608, 'hows': 2609, 'distressful': 2610, 'englands': 2611, 'remind': 2612, 'pull': 2613, 'throw': 2614, 'sod': 2615, 'root': 2616, 'underfoot': 2617, 'laws': 2618, 'blades': 2619, 'growin': 2620, 'dare': 2621, 'show': 2622, 'caubeen': 2623, 'year': 2624, 'returning': 2625, 'store': 2626, 'ale': 2627, 'frequent': 2628, 'landlady': 2629, 'credit': 2630, 'custom': 2631, 'sovereigns': 2632, 'landladys': 2633, 'wines': 2634, 'confess': 2635, 'pardon': 2636, 'prodigal': 2637, 'caress': 2638, 'forgive': 2639, 'ofttimes': 2640, 'wondering': 2641, 'powr': 2642, 'beguile': 2643, 'teardrop': 2644, 'lilting': 2645, 'laughters': 2646, 'twinkle': 2647, 'lilt': 2648, 'seems': 2649, 'linnets': 2650, 'real': 2651, 'regret': 2652, 'throughout': 2653, 'youths': 2654, 'chance': 2655, 'spied': 2656, 'receiver': 2657, 'counted': 2658, 'penny': 2659, 'bu': 2660, 'rungum': 2661, 'chamber': 2662, 'course': 2663, 'charges': 2664, 'filled': 2665, 'ready': 2666, 'footmen': 2667, 'likewise': 2668, 'draw': 2669, 'pistol': 2670, 'couldnt': 2671, 'shoot': 2672, 'robbin': 2673, 'jailer': 2674, 'tight': 2675, 'fisted': 2676, 'army': 2677, 'stationed': 2678, 'cork': 2679, 'roamin': 2680, 'swear': 2681, 'treat': 2682, 'sportin': 2683, 'hurley': 2684, 'bollin': 2685, 'maids': 2686, 'summertime': 2687, 'pluck': 2688, 'yon': 2689}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaQZWo9AQDa6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b94ee009-654c-4e88-f594-f9d57e4b80d7"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 120, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(180)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "adam = Adam(lr=0.008)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "history = model.fit(xs, ys, epochs=100, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 6.7120 - accuracy: 0.0713\n",
            "Epoch 2/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 5.8805 - accuracy: 0.0980\n",
            "Epoch 3/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 5.1749 - accuracy: 0.1430\n",
            "Epoch 4/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 4.3282 - accuracy: 0.1997\n",
            "Epoch 5/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 3.4374 - accuracy: 0.2965\n",
            "Epoch 6/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 2.6399 - accuracy: 0.4176\n",
            "Epoch 7/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 2.0233 - accuracy: 0.5353\n",
            "Epoch 8/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.5978 - accuracy: 0.6289\n",
            "Epoch 9/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.2775 - accuracy: 0.7007\n",
            "Epoch 10/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.0576 - accuracy: 0.7505\n",
            "Epoch 11/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.9272 - accuracy: 0.7830\n",
            "Epoch 12/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.8573 - accuracy: 0.7988\n",
            "Epoch 13/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.8662 - accuracy: 0.7896\n",
            "Epoch 14/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.9649 - accuracy: 0.7601\n",
            "Epoch 15/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.1936 - accuracy: 0.6946\n",
            "Epoch 16/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.1003 - accuracy: 0.7176\n",
            "Epoch 17/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.9247 - accuracy: 0.7640\n",
            "Epoch 18/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.7985 - accuracy: 0.7976\n",
            "Epoch 19/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.7304 - accuracy: 0.8160\n",
            "Epoch 20/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.7037 - accuracy: 0.8245\n",
            "Epoch 21/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6656 - accuracy: 0.8301\n",
            "Epoch 22/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6789 - accuracy: 0.8275\n",
            "Epoch 23/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.7939 - accuracy: 0.7937\n",
            "Epoch 24/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.3165 - accuracy: 0.6587\n",
            "Epoch 25/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.3767 - accuracy: 0.6411\n",
            "Epoch 26/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.0282 - accuracy: 0.7267\n",
            "Epoch 27/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.8504 - accuracy: 0.7790\n",
            "Epoch 28/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.7228 - accuracy: 0.8092\n",
            "Epoch 29/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6594 - accuracy: 0.8286\n",
            "Epoch 30/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6338 - accuracy: 0.8372\n",
            "Epoch 31/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6072 - accuracy: 0.8425\n",
            "Epoch 32/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.5900 - accuracy: 0.8461\n",
            "Epoch 33/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.5928 - accuracy: 0.8457\n",
            "Epoch 34/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6027 - accuracy: 0.8427\n",
            "Epoch 35/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.9454 - accuracy: 0.7544\n",
            "Epoch 36/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 2.0681 - accuracy: 0.5240\n",
            "Epoch 37/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.4742 - accuracy: 0.6279\n",
            "Epoch 38/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.0038 - accuracy: 0.7324\n",
            "Epoch 39/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.7763 - accuracy: 0.7975\n",
            "Epoch 40/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6719 - accuracy: 0.8237\n",
            "Epoch 41/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6226 - accuracy: 0.8386\n",
            "Epoch 42/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6043 - accuracy: 0.8427\n",
            "Epoch 43/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.5856 - accuracy: 0.8449\n",
            "Epoch 44/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.5673 - accuracy: 0.8471\n",
            "Epoch 45/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.5641 - accuracy: 0.8472\n",
            "Epoch 46/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.5608 - accuracy: 0.8492\n",
            "Epoch 47/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.5647 - accuracy: 0.8471\n",
            "Epoch 48/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.9817 - accuracy: 0.7513\n",
            "Epoch 49/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 2.4792 - accuracy: 0.4627\n",
            "Epoch 50/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.5268 - accuracy: 0.6182\n",
            "Epoch 51/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.0153 - accuracy: 0.7286\n",
            "Epoch 52/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.8122 - accuracy: 0.7821\n",
            "Epoch 53/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6982 - accuracy: 0.8135\n",
            "Epoch 54/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6377 - accuracy: 0.8330\n",
            "Epoch 55/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6002 - accuracy: 0.8418\n",
            "Epoch 56/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.5754 - accuracy: 0.8469\n",
            "Epoch 57/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.5594 - accuracy: 0.8487\n",
            "Epoch 58/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.5589 - accuracy: 0.8483\n",
            "Epoch 59/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.5687 - accuracy: 0.8457\n",
            "Epoch 60/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.8300 - accuracy: 0.7779\n",
            "Epoch 61/100\n",
            "377/377 [==============================] - 4s 12ms/step - loss: 1.9179 - accuracy: 0.5532\n",
            "Epoch 62/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.4939 - accuracy: 0.6270\n",
            "Epoch 63/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.0890 - accuracy: 0.7103\n",
            "Epoch 64/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.8496 - accuracy: 0.7697\n",
            "Epoch 65/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.7092 - accuracy: 0.8085\n",
            "Epoch 66/100\n",
            "377/377 [==============================] - 4s 12ms/step - loss: 0.6440 - accuracy: 0.8290\n",
            "Epoch 67/100\n",
            "377/377 [==============================] - 5s 12ms/step - loss: 0.6184 - accuracy: 0.8359\n",
            "Epoch 68/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.5867 - accuracy: 0.8439\n",
            "Epoch 69/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.5766 - accuracy: 0.8447\n",
            "Epoch 70/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.5854 - accuracy: 0.8422\n",
            "Epoch 71/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6141 - accuracy: 0.8357\n",
            "Epoch 72/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.8849 - accuracy: 0.7650\n",
            "Epoch 73/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.5762 - accuracy: 0.6144\n",
            "Epoch 74/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.3999 - accuracy: 0.6444\n",
            "Epoch 75/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.0368 - accuracy: 0.7206\n",
            "Epoch 76/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.8387 - accuracy: 0.7736\n",
            "Epoch 77/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.7836 - accuracy: 0.7929\n",
            "Epoch 78/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6862 - accuracy: 0.8158\n",
            "Epoch 79/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6308 - accuracy: 0.8300\n",
            "Epoch 80/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6008 - accuracy: 0.8399\n",
            "Epoch 81/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.5941 - accuracy: 0.8371\n",
            "Epoch 82/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6215 - accuracy: 0.8331\n",
            "Epoch 83/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.7274 - accuracy: 0.8039\n",
            "Epoch 84/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.9898 - accuracy: 0.7340\n",
            "Epoch 85/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.2521 - accuracy: 0.6759\n",
            "Epoch 86/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.0723 - accuracy: 0.7178\n",
            "Epoch 87/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.8424 - accuracy: 0.7736\n",
            "Epoch 88/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.7050 - accuracy: 0.8081\n",
            "Epoch 89/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6517 - accuracy: 0.8244\n",
            "Epoch 90/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6273 - accuracy: 0.8313\n",
            "Epoch 91/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6027 - accuracy: 0.8380\n",
            "Epoch 92/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.5901 - accuracy: 0.8409\n",
            "Epoch 93/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6060 - accuracy: 0.8354\n",
            "Epoch 94/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6509 - accuracy: 0.8221\n",
            "Epoch 95/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.9191 - accuracy: 0.7526\n",
            "Epoch 96/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.2094 - accuracy: 0.6931\n",
            "Epoch 97/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 1.0555 - accuracy: 0.7200\n",
            "Epoch 98/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.8429 - accuracy: 0.7716\n",
            "Epoch 99/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.7174 - accuracy: 0.8040\n",
            "Epoch 100/100\n",
            "377/377 [==============================] - 4s 11ms/step - loss: 0.6538 - accuracy: 0.8207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehwoBsO2ZL7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfTOHOMlZPWc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "e65b6834-813c-439d-9596-7a116a61479b"
      },
      "source": [
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXkKS2zFuq8X",
        "colab_type": "text"
      },
      "source": [
        "Character based RNN sequence generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxfSFa06uze1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "8aae0608-e8e8-4ecb-8c11-64d425a635e9"
      },
      "source": [
        "seed_text = \"I've got a bad feeling about this\"\n",
        "next_words = 120\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])\n",
        "\ttoken_list = pad_sequences(token_list, maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-6889ba2860e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtoken_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseed_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtoken_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_sequence_len\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pre'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxuV2TGbup9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmHfaLKlvzL8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "43ef6565-9517-4216-8d18-9922246bbea9"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('/content/shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC7Pz-95v7hH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85cac436-0a0c-4721-e4ff-39304093626a"
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZGEeHLnwfcR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7d4d915f-70ac-4f6b-f341-2b96d670abf1"
      },
      "source": [
        "# Take a look at the first 20 characters in text\n",
        "print(text[:20])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Befor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwx6OWwowqLr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5019b8ef-de09-42b5-bfba-fdd3e76d38b7"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print ('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWRbRZlYw_y3",
        "colab_type": "text"
      },
      "source": [
        "Vectorize the text -two lookup tables\n",
        "\n",
        "*   mapping characters to numbers\n",
        "*   mapping numbers to characters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C801tNLrw2eT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "# dict for character to number index\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "# numpy version of characters\n",
        "idx2char = np.array(vocab)\n",
        "# mapping each character to a number index\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXgk7TxB-cmW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4620ea64-5ab6-4b81-8ec6-ff44214d6505"
      },
      "source": [
        "print(text[:10])\n",
        "print(text_as_int[:10]) # one character --> one number"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citi\n",
            "[18 47 56 57 58  1 15 47 58 47]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DND6VSIR_Y3y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "3c1cbefa-304e-4804-bd0d-f212a77ee694"
      },
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '$' :   3,\n",
            "  '&' :   4,\n",
            "  \"'\" :   5,\n",
            "  ',' :   6,\n",
            "  '-' :   7,\n",
            "  '.' :   8,\n",
            "  '3' :   9,\n",
            "  ':' :  10,\n",
            "  ';' :  11,\n",
            "  '?' :  12,\n",
            "  'A' :  13,\n",
            "  'B' :  14,\n",
            "  'C' :  15,\n",
            "  'D' :  16,\n",
            "  'E' :  17,\n",
            "  'F' :  18,\n",
            "  'G' :  19,\n",
            "  ...\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9czclgM_8uy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9dfdaf97-bbcd-4390-8124-91d65968778b"
      },
      "source": [
        "# Show how the first 13 characters from the text are mapped to integers\n",
        "print ('{} ---- characters mapped to int ---- > {}'.format(text[:13], text_as_int[:13]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen ---- characters mapped to int ---- > [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntQ7j_UzCiwo",
        "colab_type": "text"
      },
      "source": [
        "For each input sequence, the corresponding targets contain the same length of text, except shifted one character to the right.\n",
        "e.g. Hell --> ello <p>\n",
        "So we break the text into chunks of seq_length+1 (holds X --> Y) <P>\n",
        "Use the tf.data.Dataset.from_tensor_slices function to convert the text vector into a stream of character indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VILZWhWLALSl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "a024ffc9-d9ef-4fb2-883f-6828af1a2987"
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "  print('{} ----> {}'.format(i, idx2char[i]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18 ----> F\n",
            "47 ----> i\n",
            "56 ----> r\n",
            "57 ----> s\n",
            "58 ----> t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCo7K67eDO63",
        "colab_type": "text"
      },
      "source": [
        "The batch method lets us easily convert these individual characters to sequences of the desired size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s49u0f5JCUx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "fff507f3-d8e6-4d1c-962b-3bf5db5c767a"
      },
      "source": [
        "print(text[:200])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib50wSSHEFsv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "2fc09f38-2a49-421f-d6af-81ed4f2ab77b"
      },
      "source": [
        "# devide the whole char sequence into chunks with pre-set batch size\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I11wrPSHExMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the input sequence and the label sequence\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AjeNEVZHAcg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "567571d3-83c5-41a8-9c39-b7668c996ea6"
      },
      "source": [
        "# show the first two input sequence and target\n",
        "for input_example, target_example in  dataset.take(2):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target data: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "Input data:  'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you '\n",
            "Target data: 're all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24wjtmPFH553",
        "colab_type": "text"
      },
      "source": [
        "Each index of these vectors are processed as one time step. For the input at time step 0, the model receives the index for \"F\" and trys to predict the index for \"i\" as the next character. At the next timestep, it does the same thing but the RNN considers the previous step context in addition to the current input character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpF8g3NvHsGZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "a1b0fc02-1eb1-4cca-9457-c93f9121905b"
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input: 39 ('a')\n",
            "  expected output: 56 ('r')\n",
            "Step    1\n",
            "  input: 56 ('r')\n",
            "  expected output: 43 ('e')\n",
            "Step    2\n",
            "  input: 43 ('e')\n",
            "  expected output: 1 (' ')\n",
            "Step    3\n",
            "  input: 1 (' ')\n",
            "  expected output: 39 ('a')\n",
            "Step    4\n",
            "  input: 39 ('a')\n",
            "  expected output: 50 ('l')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-a42ln-UgRj",
        "colab_type": "text"
      },
      "source": [
        "Create training batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9kJzlaWUbJw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b36be1c-044b-40fb-9bce-122ef0e0e4ec"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nogtnXC8U2iB",
        "colab_type": "text"
      },
      "source": [
        "Build the RNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDMs72vWUskS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab) # 65 unique chars\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC_NkH77U5kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzs0Ys9Wk4L_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "000cc9fc-3cea-4d1c-9418-430201ebd852"
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "gru_6 (GRU)                  (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (64, None, 1024)          0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMh3UTPDrOl7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bac8e67b-4873-4dde-c7b5-36f33a1cb8ac"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(f'input batch shape: {input_example_batch.shape}, vocab-char size: {len(vocab)}')\n",
        "  print(example_batch_predictions.shape, \"= ( batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input batch shape: (64, 100), vocab-char size: 65\n",
            "(64, 100, 65) = ( batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9nJ_-m7uh0n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "481c69a9-2838-4e96-9939-30353c1abea5"
      },
      "source": [
        "# get the predictioin of 1 data point, one batch has 64 points\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "print(f'the input seq:\\n {np.array(input_example_batch[0])}')\n",
        "print(f'the output predict:\\n {example_batch_predictions[0]}, \\n total predict: {len(example_batch_predictions[0])}, \\n equal to the length of the input sequence')\n",
        "# reduce to vector\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "print(f'the index with highest logit output: {(sampled_indices)}')\n",
        "print(\"Input: \\n\",f'{\"\".join(idx2char[input_example_batch[0]])}')\n",
        "print(\"\\n\")\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the input seq:\n",
            " [39 56 50 47 49 43  1 19 39 59 52 58  6  0 13 52 42  1 40 63  1 58 46 43\n",
            "  1 61 53 56 58 46  1 39 52 42  1 46 53 52 53 59 56  1 53 44  1 46 47 51\n",
            " 57 43 50 44  6  0 15 53 51 54 56 47 57 47 52 45  1 39 50 50  1 58 46 39\n",
            " 58  1 51 39 63  1 40 43  1 57 61 53 56 52  1 53 56  1 57 39 47 42  6  0\n",
            " 20 47 57  1]\n",
            "the output predict:\n",
            " [[ -0.8390355    4.4737697    0.1918157  ...  -2.59655      2.5302503\n",
            "   -6.382758  ]\n",
            " [ -0.74475193   4.7973785   -0.15161017 ...  -5.188004     0.2535339\n",
            "   -8.701349  ]\n",
            " [  0.45190018   7.2506604    0.46644422 ...  -6.855944     7.792626\n",
            "   -8.680688  ]\n",
            " ...\n",
            " [ -6.9010296   -4.448863    -4.3762355  ...   1.7298471   -6.9617457\n",
            "    1.5433046 ]\n",
            " [  5.0925665   13.732006     0.2772495  ... -10.804308    -4.159179\n",
            "   -9.538286  ]\n",
            " [ -5.206641    -2.7089977   -4.1203194  ...  -8.104589     1.920866\n",
            "   -3.1109924 ]], \n",
            " total predict: 100, \n",
            " equal to the length of the input sequence\n",
            "the index with highest logit output: [47 43  5 52 43  1 58 47 59 52 58 10  0 13 52 42  1 41 47  1 58 46 47  1\n",
            " 56 46 56 50 46 63 39 52 42  1 46 47 52 53 59 56  1 53 44  1 46 43 57  8\n",
            " 43 50 44  6  0 31 53 51 43 39 53 57 53 52 45  1 50 52 50  1 61 53 47 58\n",
            "  1 54 43 63  1 40 43  1 57 43 47 56 52  1 39 59  1 57 39 60 42  6  1 35\n",
            " 53 57  1 41]\n",
            "Input: \n",
            " arlike Gaunt,\n",
            "And by the worth and honour of himself,\n",
            "Comprising all that may be sworn or said,\n",
            "His \n",
            "\n",
            "\n",
            "Next Char Predictions: \n",
            " \"ie'ne tiunt:\\nAnd ci thi rhrlhyand hinour of hes.elf,\\nSomeaosong lnl woit pey be seirn au savd, Wos c\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqXtKJI1k47h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1SwevCyPHQA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e32030d4-510c-44e1-82d2-637e63e126ee"
      },
      "source": [
        "print(f'Y(batch, sequence):{target_example_batch.shape}, Y-hat(batch, sequence, vocab):{example_batch_predictions.shape}')\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"scalar_loss: \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y(batch, sequence):(64, 100), Y-hat(batch, sequence, vocab):(64, 100, 65)\n",
            "scalar_loss:  0.7694741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNk47D6Tloe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Eh2FyRQl2KP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq85AiFDl3CS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "5cbbc80e-cea1-4547-9edd-fba6c6eda935"
      },
      "source": [
        "EPOCHS = 20\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 8s 44ms/step - loss: 1.0092\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.9921\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.9758\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.9637\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.9499\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.9409\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.9314\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.9244\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.9198\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.9123\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.9076\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.9036\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.8996\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.8989\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.8957\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.8928\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.8929\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.8933\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.8909\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.8904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkY0paXxnPcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbsh7TutnVDV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "a4c42b88-3af9-4f6b-9971-ce562c4919a4"
      },
      "source": [
        "plot_graphs(history, 'loss')"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMLCaHnNmE_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_predict = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model_predict.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model_predict.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B74K5n8NWtQ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4018272a-b370-49c7-c9bc-30f00e6c0d98"
      },
      "source": [
        "num_generate = 2000\n",
        "start_string = u\"ROMEO: \" # 7 chars\n",
        "# char to sequence\n",
        "input_eval = [char2idx[s] for s in start_string]\n",
        "input_eval = tf.expand_dims(input_eval, 0)\n",
        "print(input_eval.numpy())\n",
        "text_gen = []\n",
        "# higer temp more rush text, lower temp more predictable text\n",
        "temp = 0.8\n",
        "model_predict.reset_states()\n",
        "\n",
        "for i in range(num_generate):\n",
        "  predictions = model_predict(input_eval)\n",
        "  predictions = tf.squeeze(predictions, 0)\n",
        "  predictions = predictions / temp\n",
        "  predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "  input_eval = tf.expand_dims([predicted_id], 0)\n",
        "  text_gen.append(idx2char[predicted_id])\n",
        "\n",
        "output_text = start_string+\"\".join(text_gen)\n",
        "print(output_text)"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[30 27 25 17 27 10  1]]\n",
            "ROMEO: I have a brother treeb\n",
            "'Tis dead her throne in the best, and then one want there's\n",
            "have consumed with consequence is the intent\n",
            "That they do happe sweet with words.\n",
            "\n",
            "SICINIUS:\n",
            "Where is the proportion of your will?\n",
            "\n",
            "KING RICHARD III:\n",
            "Hear me.\n",
            "\n",
            "ANTONIO:\n",
            "What did you do\n",
            "But need you only your grace we have spent near slow;\n",
            "So die without-sin, for this world entrails\n",
            "That rail'd whthus was the tribunes of the make.\n",
            "\n",
            "LUCIO:\n",
            "My father is derave;\n",
            "If pats that my followers from the Tower now,--\n",
            "\n",
            "SICINIUS:\n",
            "Well, girl; what said I should remain it so.\n",
            "\n",
            "BIANCA:\n",
            "Is be pluck out, of mockery, or any things as to jettle.\n",
            "If thou may part; ench shows if an assurance,\n",
            "That is not Richard, how a husband!\n",
            "I do attend your worship. For mine own part,\n",
            "When I should die with a fall poor city, fairte, and they are so let it\n",
            "bless us; which you have accountan'd the very pin\n",
            "That was my fellow unhaly hall,\n",
            "Thou shalt be sent anon,\n",
            "And watchers louder than I would pray for your love.\n",
            "\n",
            "MARIANA:\n",
            "You are a poor remorse of her; yet who think you?\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Is it more leisure? Juliet, it is a devil:\n",
            "The instrument of that very widow!\n",
            "\n",
            "Provost:\n",
            "A bawd, so night!\n",
            "Take leave until within the world.\n",
            "\n",
            "Second Murderer:\n",
            "And therefore and my mind. Nay, but they are of you,\n",
            "And that temples.\n",
            "\n",
            "COMINIUS:\n",
            "The case is this your country was the hungry.\n",
            "\n",
            "CAPULET:\n",
            "Where is he won? behalf I think and laurest,\n",
            "As that to you both made and speak for the third,\n",
            "When I should be as haste you will deserve:\n",
            "My lord is likeward we have recorded unto your hands:\n",
            "Now, feison we shall share the grows!\n",
            "\n",
            "GLOUCESTER:\n",
            "Look to the close intents that she be holy, but that your honour tame\n",
            "Me seem to be embraced and to be thy heart.\n",
            "\n",
            "DERBY:\n",
            "What then?\n",
            "\n",
            "MOPSA:\n",
            "I would think we are given and break one of the bastard;\n",
            "Not as the villain was so die: I may not speak.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "Ay, boy! speak to the war, come, like a man's bear, what trouble\n",
            "In boltse lives shall be the freshest sensoman bear.\n",
            "\n",
            "MENENIUS:\n",
            "Where is the prov\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N85KvSame2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 1000\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qnv2J9KmfwN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "outputId": "a6cb8d90-0589-4363-c0ff-a9119e1410c8"
      },
      "source": [
        "print(generate_text(model, start_string=u\"ROMEO: \"))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROMEO: who's of\n",
            "they harl in his mistress, you have\n",
            "Because the one that hand forlow to live.\n",
            "\n",
            "PETRUCHIO:\n",
            "A husband by silenck! let me not say.\n",
            "\n",
            "Bease;\n",
            "And, Garder, thou shalt but master truth in the marsiness.\n",
            "When caps the royal sucrue sister, so his nought Warwick discharged\n",
            "Of your blood, they last love.\n",
            "\n",
            "PAULINA:\n",
            "Be instrument thy lips mage\n",
            "He'll seem the cation?.\n",
            "\n",
            "HORTENSIO:\n",
            "In some fools your son liege, uncle's realm, think'st\n",
            "To wail'd this gare ofrul hands, and cheerfully make you as you a word 'Werm too: they must King Richard, in joy\n",
            "The gods along imprisonment crown Bornign.\n",
            "\n",
            "KING EDWARD IV:\n",
            "Well, besides, good Came by his father; call'd no harm and him:\n",
            "And all the strength return to be our\n",
            "presence, and Camillo thou comest thou, this little horse than I so 'greed.\n",
            "\n",
            "Shooth,\n",
            "But you stay at once, whilst sorrow came,\n",
            "And the fathers mounted arrey too dukedom.\n",
            "Let him be, in cursed hate\n",
            "But your woes should piece en our hateful liege\n",
            "In sig infurrent were elsewhere\n",
            "As they are come \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ilh1pY0vgAcD",
        "colab_type": "text"
      },
      "source": [
        "Customize the training loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F34rhAkwgCzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_custom = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB_0lXGTgtvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hanYv585g474",
        "colab_type": "text"
      },
      "source": [
        "Build the optimized loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlS3YCcGg136",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, target):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model_custom(inp)\n",
        "    loss = tf.reduce_mean(\n",
        "        tf.keras.losses.sparse_categorical_crossentropy(\n",
        "            target, predictions, from_logits=True))\n",
        "  grads = tape.gradient(loss, model_custom.trainable_variables) # get the gradients\n",
        "  # pipeline the gradients to the optimizer\n",
        "  optimizer.apply_gradients(zip(grads, model_custom.trainable_variables))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMscUFeivocQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92562f90-e7cc-4482-83f0-ca3e5729fb0f"
      },
      "source": [
        "import time\n",
        "\n",
        "# Training step\n",
        "EPOCHS = 20\n",
        "record = []\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  # initializing the hidden state at the start of every epoch\n",
        "  # initally hidden is None\n",
        "  hidden = model_custom.reset_states()\n",
        "\n",
        "  for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "    loss = train_step(inp, target)\n",
        "\n",
        "    if batch_n % 100 == 0:\n",
        "      template = 'Epoch {} Batch {} Loss {}'\n",
        "      print(template.format(epoch+1, batch_n, loss))\n",
        "\n",
        "  # saving (checkpoint) the model every 5 epochs\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    model_custom.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "  print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n",
        "  print ('Time taken for 1 epoch {:.2f} sec\\n'.format(time.time() - start))\n",
        "  record.append(loss)\n",
        "\n",
        "model_custom.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "history = {'loss':record}"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.4267826080322266\n",
            "Epoch 1 Batch 100 Loss 2.225112199783325\n",
            "Epoch 1 Loss 2.1967\n",
            "Time taken for 1 epoch 8.64 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.372197151184082\n",
            "Epoch 2 Batch 100 Loss 2.1599318981170654\n",
            "Epoch 2 Loss 2.2151\n",
            "Time taken for 1 epoch 8.27 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 2.3310418128967285\n",
            "Epoch 3 Batch 100 Loss 2.2164053916931152\n",
            "Epoch 3 Loss 2.1766\n",
            "Time taken for 1 epoch 8.44 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 2.2884175777435303\n",
            "Epoch 4 Batch 100 Loss 2.1578876972198486\n",
            "Epoch 4 Loss 2.1619\n",
            "Time taken for 1 epoch 8.49 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 2.306990623474121\n",
            "Epoch 5 Batch 100 Loss 2.1954758167266846\n",
            "Epoch 5 Loss 2.1380\n",
            "Time taken for 1 epoch 8.31 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 2.276719570159912\n",
            "Epoch 6 Batch 100 Loss 2.149425745010376\n",
            "Epoch 6 Loss 2.1122\n",
            "Time taken for 1 epoch 8.20 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 2.336693525314331\n",
            "Epoch 7 Batch 100 Loss 2.117783784866333\n",
            "Epoch 7 Loss 2.0686\n",
            "Time taken for 1 epoch 8.35 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 2.2708041667938232\n",
            "Epoch 8 Batch 100 Loss 2.1475718021392822\n",
            "Epoch 8 Loss 2.1466\n",
            "Time taken for 1 epoch 8.46 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 2.3075661659240723\n",
            "Epoch 9 Batch 100 Loss 2.128079414367676\n",
            "Epoch 9 Loss 2.0579\n",
            "Time taken for 1 epoch 8.19 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 2.320585250854492\n",
            "Epoch 10 Batch 100 Loss 2.0575814247131348\n",
            "Epoch 10 Loss 2.1265\n",
            "Time taken for 1 epoch 8.24 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 2.2582924365997314\n",
            "Epoch 11 Batch 100 Loss 2.1153249740600586\n",
            "Epoch 11 Loss 2.0018\n",
            "Time taken for 1 epoch 8.11 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 2.2425153255462646\n",
            "Epoch 12 Batch 100 Loss 2.0461854934692383\n",
            "Epoch 12 Loss 2.0295\n",
            "Time taken for 1 epoch 8.47 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 2.233978748321533\n",
            "Epoch 13 Batch 100 Loss 2.0512399673461914\n",
            "Epoch 13 Loss 1.9604\n",
            "Time taken for 1 epoch 8.18 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 2.2557060718536377\n",
            "Epoch 14 Batch 100 Loss 2.0417428016662598\n",
            "Epoch 14 Loss 2.0364\n",
            "Time taken for 1 epoch 8.33 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 2.1997671127319336\n",
            "Epoch 15 Batch 100 Loss 2.042126178741455\n",
            "Epoch 15 Loss 2.0099\n",
            "Time taken for 1 epoch 8.19 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 2.1787266731262207\n",
            "Epoch 16 Batch 100 Loss 1.9888955354690552\n",
            "Epoch 16 Loss 2.0006\n",
            "Time taken for 1 epoch 8.15 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 2.216714859008789\n",
            "Epoch 17 Batch 100 Loss 2.0128283500671387\n",
            "Epoch 17 Loss 2.0514\n",
            "Time taken for 1 epoch 8.42 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 2.168346881866455\n",
            "Epoch 18 Batch 100 Loss 1.9324628114700317\n",
            "Epoch 18 Loss 2.0287\n",
            "Time taken for 1 epoch 8.26 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 2.154078483581543\n",
            "Epoch 19 Batch 100 Loss 1.972965121269226\n",
            "Epoch 19 Loss 1.9483\n",
            "Time taken for 1 epoch 8.20 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 2.1343483924865723\n",
            "Epoch 20 Batch 100 Loss 1.923933744430542\n",
            "Epoch 20 Loss 1.9192\n",
            "Time taken for 1 epoch 8.67 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-uS5-IKpR7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "d7760312-8f21-4c9b-d3ef-93d5df88f21f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history['loss'])\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBkTuSCFpbOw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "b948ad3e-b32a-4e07-aedb-a81d75a8f289"
      },
      "source": [
        "model_predict = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model_predict.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model_predict.build(tf.TensorShape([1, None]))\n",
        "\n",
        "num_generate = 1000\n",
        "start_string = u\"ROMEO: \" # 7 chars\n",
        "# char to sequence\n",
        "input_eval = [char2idx[s] for s in start_string]\n",
        "input_eval = tf.expand_dims(input_eval, 0)\n",
        "print(input_eval.numpy())\n",
        "text_gen = []\n",
        "# higer temp more rush text, lower temp more predictable text\n",
        "temp = 1.0\n",
        "model_predict.reset_states()\n",
        "\n",
        "for i in range(num_generate):\n",
        "  predictions = model_predict(input_eval)\n",
        "  predictions = tf.squeeze(predictions, 0)\n",
        "  predictions = predictions / temp\n",
        "  predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "  input_eval = tf.expand_dims([predicted_id], 0)\n",
        "  text_gen.append(idx2char[predicted_id])\n",
        "\n",
        "output_text = start_string+\"\".join(text_gen)\n",
        "print(output_text)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[30 27 25 17 27 10  1]]\n",
            "ROMEO: Thelay petime.\n",
            "Hourd noy tow''l triveir.\n",
            "\n",
            "QUEENTES:\n",
            "If se ol midrere, owimbemono song it of hary home tren\n",
            "To breawermy of 'tly king the worco. Worinsseed my of a blermolr your,--as arloy ie blowarst. Briot me trewinco me dou haty efforgoospize\n",
            "Te troursere good you to thy quee ingen. Totely, we lovowis thie yol ast orio.\n",
            "Then, ard the stely some my splothen, our arly ight in.\n",
            "Whe hold the dightillst popeait: Butisell? in thour then heyor's! Totturbar sople to s you ore nour greak or's\n",
            "WhIN Blore ther'de, telf to her herfulperomsot for your not\n",
            "Tiilletave corsteritiir, wordil;\n",
            "In Ein ollee it mo.\n",
            "\n",
            "KILLO:\n",
            "Cilistirnttry arse, my Mormitime, aury tley thoun sstelie,\n",
            "Their tremy moul dosern in witerft to Edwith prome Porvoysinisune\n",
            "To poom saro it wat\n",
            "To howheris thy for mistar mores me tels,\n",
            "Brefment, time, bedse, to treys.\n",
            "O fe llfoles. Wireane thou was, a with ny homeror is Bor stroup isturess.\n",
            "\n",
            "Proot or hom onail you; one.\n",
            "He mado, womy le, ander'd ream so ceer-ark mordenthif tomue thei\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWXEEoMjE2sT",
        "colab_type": "text"
      },
      "source": [
        "Shakespeare problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l4xH36qE4UA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8h6gKWTFBRx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "71d889e6-d525-4bd9-ea05-dd6288694175"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
        "    -O /content/sonnets.txt\n",
        "data = open('/content/sonnets.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-10 23:34:52--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 172.217.203.128, 74.125.141.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93578 (91K) [text/plain]\n",
            "Saving to: ‘/content/sonnets.txt’\n",
            "\n",
            "\r/content/sonnets.tx   0%[                    ]       0  --.-KB/s               \r/content/sonnets.tx 100%[===================>]  91.38K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-07-10 23:34:52 (61.5 MB/s) - ‘/content/sonnets.txt’ saved [93578/93578]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN28sJFHFOrw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "fa55e654-c9f2-4e2e-a837-6aa4d4135cad"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences = True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 10, 100)           321100    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 10, 512)           731136    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 10, 512)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 128)               328192    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1605)              207045    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3211)              5156866   \n",
            "=================================================================\n",
            "Total params: 6,744,339\n",
            "Trainable params: 6,744,339\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vmBJjpJFZvt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e852c6a1-0ae5-449e-a623-c435827b7615"
      },
      "source": [
        "history = model.fit(predictors, label, epochs=200, verbose=1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 6.9279 - accuracy: 0.0209\n",
            "Epoch 2/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 6.5030 - accuracy: 0.0211\n",
            "Epoch 3/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 6.4005 - accuracy: 0.0251\n",
            "Epoch 4/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 6.2925 - accuracy: 0.0290\n",
            "Epoch 5/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 6.2229 - accuracy: 0.0333\n",
            "Epoch 6/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 6.1589 - accuracy: 0.0368\n",
            "Epoch 7/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 6.0950 - accuracy: 0.0367\n",
            "Epoch 8/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 6.0328 - accuracy: 0.0408\n",
            "Epoch 9/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 5.9644 - accuracy: 0.0438\n",
            "Epoch 10/200\n",
            "484/484 [==============================] - 7s 13ms/step - loss: 5.8916 - accuracy: 0.0476\n",
            "Epoch 11/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 5.8155 - accuracy: 0.0501\n",
            "Epoch 12/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 5.7314 - accuracy: 0.0522\n",
            "Epoch 13/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 5.6573 - accuracy: 0.0581\n",
            "Epoch 14/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 5.5811 - accuracy: 0.0592\n",
            "Epoch 15/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 5.5109 - accuracy: 0.0642\n",
            "Epoch 16/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 5.4356 - accuracy: 0.0693\n",
            "Epoch 17/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 5.3662 - accuracy: 0.0726\n",
            "Epoch 18/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 5.2923 - accuracy: 0.0790\n",
            "Epoch 19/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 5.2169 - accuracy: 0.0852\n",
            "Epoch 20/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 5.1438 - accuracy: 0.0902\n",
            "Epoch 21/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 5.0724 - accuracy: 0.0947\n",
            "Epoch 22/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 4.9996 - accuracy: 0.1004\n",
            "Epoch 23/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 4.9202 - accuracy: 0.1096\n",
            "Epoch 24/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 4.8472 - accuracy: 0.1116\n",
            "Epoch 25/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 4.7629 - accuracy: 0.1204\n",
            "Epoch 26/200\n",
            "484/484 [==============================] - 7s 13ms/step - loss: 4.6896 - accuracy: 0.1279\n",
            "Epoch 27/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 4.6101 - accuracy: 0.1355\n",
            "Epoch 28/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 4.5245 - accuracy: 0.1427\n",
            "Epoch 29/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 4.4432 - accuracy: 0.1539\n",
            "Epoch 30/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 4.3526 - accuracy: 0.1618\n",
            "Epoch 31/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 4.2814 - accuracy: 0.1718\n",
            "Epoch 32/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 4.1929 - accuracy: 0.1816\n",
            "Epoch 33/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 4.1104 - accuracy: 0.1962\n",
            "Epoch 34/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 4.0318 - accuracy: 0.2066\n",
            "Epoch 35/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 3.9492 - accuracy: 0.2202\n",
            "Epoch 36/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 3.8689 - accuracy: 0.2319\n",
            "Epoch 37/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 3.7868 - accuracy: 0.2462\n",
            "Epoch 38/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 3.7107 - accuracy: 0.2590\n",
            "Epoch 39/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 3.6358 - accuracy: 0.2764\n",
            "Epoch 40/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 3.5499 - accuracy: 0.2947\n",
            "Epoch 41/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 3.4791 - accuracy: 0.3068\n",
            "Epoch 42/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 3.4025 - accuracy: 0.3245\n",
            "Epoch 43/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 3.3330 - accuracy: 0.3397\n",
            "Epoch 44/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 3.2654 - accuracy: 0.3557\n",
            "Epoch 45/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 3.1907 - accuracy: 0.3703\n",
            "Epoch 46/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 3.1179 - accuracy: 0.3886\n",
            "Epoch 47/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 3.0488 - accuracy: 0.4078\n",
            "Epoch 48/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 2.9919 - accuracy: 0.4149\n",
            "Epoch 49/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 2.9248 - accuracy: 0.4334\n",
            "Epoch 50/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.8561 - accuracy: 0.4474\n",
            "Epoch 51/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.8008 - accuracy: 0.4663\n",
            "Epoch 52/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.7404 - accuracy: 0.4767\n",
            "Epoch 53/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.6858 - accuracy: 0.4904\n",
            "Epoch 54/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.6293 - accuracy: 0.5023\n",
            "Epoch 55/200\n",
            "484/484 [==============================] - 7s 15ms/step - loss: 2.5750 - accuracy: 0.5152\n",
            "Epoch 56/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 2.5270 - accuracy: 0.5292\n",
            "Epoch 57/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.4754 - accuracy: 0.5369\n",
            "Epoch 58/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.4312 - accuracy: 0.5464\n",
            "Epoch 59/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.3826 - accuracy: 0.5579\n",
            "Epoch 60/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.3224 - accuracy: 0.5720\n",
            "Epoch 61/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 2.2821 - accuracy: 0.5814\n",
            "Epoch 62/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.2355 - accuracy: 0.5921\n",
            "Epoch 63/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.2097 - accuracy: 0.5942\n",
            "Epoch 64/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.1788 - accuracy: 0.6023\n",
            "Epoch 65/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.1345 - accuracy: 0.6098\n",
            "Epoch 66/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.0896 - accuracy: 0.6222\n",
            "Epoch 67/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.0503 - accuracy: 0.6318\n",
            "Epoch 68/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 2.0108 - accuracy: 0.6371\n",
            "Epoch 69/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.9784 - accuracy: 0.6471\n",
            "Epoch 70/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.9504 - accuracy: 0.6541\n",
            "Epoch 71/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.9256 - accuracy: 0.6581\n",
            "Epoch 72/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.9019 - accuracy: 0.6603\n",
            "Epoch 73/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.8586 - accuracy: 0.6746\n",
            "Epoch 74/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.8220 - accuracy: 0.6779\n",
            "Epoch 75/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.8056 - accuracy: 0.6826\n",
            "Epoch 76/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.7795 - accuracy: 0.6858\n",
            "Epoch 77/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.7530 - accuracy: 0.6928\n",
            "Epoch 78/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.7267 - accuracy: 0.7035\n",
            "Epoch 79/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.6972 - accuracy: 0.7053\n",
            "Epoch 80/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.6801 - accuracy: 0.7075\n",
            "Epoch 81/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.6560 - accuracy: 0.7108\n",
            "Epoch 82/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.6197 - accuracy: 0.7197\n",
            "Epoch 83/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.6029 - accuracy: 0.7237\n",
            "Epoch 84/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.5851 - accuracy: 0.7280\n",
            "Epoch 85/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.5674 - accuracy: 0.7308\n",
            "Epoch 86/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.5549 - accuracy: 0.7293\n",
            "Epoch 87/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.5348 - accuracy: 0.7345\n",
            "Epoch 88/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.5156 - accuracy: 0.7392\n",
            "Epoch 89/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.4862 - accuracy: 0.7462\n",
            "Epoch 90/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.4749 - accuracy: 0.7471\n",
            "Epoch 91/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.4438 - accuracy: 0.7542\n",
            "Epoch 92/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.4335 - accuracy: 0.7533\n",
            "Epoch 93/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.4267 - accuracy: 0.7547\n",
            "Epoch 94/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.4035 - accuracy: 0.7597\n",
            "Epoch 95/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.3927 - accuracy: 0.7623\n",
            "Epoch 96/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.3869 - accuracy: 0.7652\n",
            "Epoch 97/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.3648 - accuracy: 0.7660\n",
            "Epoch 98/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.3536 - accuracy: 0.7674\n",
            "Epoch 99/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.3427 - accuracy: 0.7712\n",
            "Epoch 100/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.3169 - accuracy: 0.7764\n",
            "Epoch 101/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.3043 - accuracy: 0.7784\n",
            "Epoch 102/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.2858 - accuracy: 0.7824\n",
            "Epoch 103/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.2803 - accuracy: 0.7829\n",
            "Epoch 104/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 1.2748 - accuracy: 0.7833\n",
            "Epoch 105/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 1.2681 - accuracy: 0.7813\n",
            "Epoch 106/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.2439 - accuracy: 0.7867\n",
            "Epoch 107/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.2482 - accuracy: 0.7862\n",
            "Epoch 108/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.2395 - accuracy: 0.7855\n",
            "Epoch 109/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.2270 - accuracy: 0.7899\n",
            "Epoch 110/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.2104 - accuracy: 0.7928\n",
            "Epoch 111/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.1963 - accuracy: 0.7982\n",
            "Epoch 112/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.1954 - accuracy: 0.7928\n",
            "Epoch 113/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.1771 - accuracy: 0.7987\n",
            "Epoch 114/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.1752 - accuracy: 0.7969\n",
            "Epoch 115/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.1835 - accuracy: 0.7929\n",
            "Epoch 116/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.1577 - accuracy: 0.8022\n",
            "Epoch 117/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.1504 - accuracy: 0.8028\n",
            "Epoch 118/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.1335 - accuracy: 0.8041\n",
            "Epoch 119/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.1295 - accuracy: 0.8046\n",
            "Epoch 120/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.1273 - accuracy: 0.8075\n",
            "Epoch 121/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.1066 - accuracy: 0.8099\n",
            "Epoch 122/200\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 1.1058 - accuracy: 0.8080\n",
            "Epoch 123/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.1056 - accuracy: 0.8065\n",
            "Epoch 124/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.0971 - accuracy: 0.8078\n",
            "Epoch 125/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.0894 - accuracy: 0.8122\n",
            "Epoch 126/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.0786 - accuracy: 0.8139\n",
            "Epoch 127/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.0746 - accuracy: 0.8121\n",
            "Epoch 128/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.0644 - accuracy: 0.8162\n",
            "Epoch 129/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.0724 - accuracy: 0.8130\n",
            "Epoch 130/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.0594 - accuracy: 0.8143\n",
            "Epoch 131/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.0473 - accuracy: 0.8170\n",
            "Epoch 132/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.0435 - accuracy: 0.8185\n",
            "Epoch 133/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.0380 - accuracy: 0.8205\n",
            "Epoch 134/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.0339 - accuracy: 0.8157\n",
            "Epoch 135/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.0329 - accuracy: 0.8166\n",
            "Epoch 136/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.0404 - accuracy: 0.8144\n",
            "Epoch 137/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.0251 - accuracy: 0.8179\n",
            "Epoch 138/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.0192 - accuracy: 0.8203\n",
            "Epoch 139/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.0038 - accuracy: 0.8221\n",
            "Epoch 140/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.9969 - accuracy: 0.8228\n",
            "Epoch 141/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.9947 - accuracy: 0.8235\n",
            "Epoch 142/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 1.0000 - accuracy: 0.8210\n",
            "Epoch 143/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.9891 - accuracy: 0.8234\n",
            "Epoch 144/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.9741 - accuracy: 0.8278\n",
            "Epoch 145/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.9848 - accuracy: 0.8249\n",
            "Epoch 146/200\n",
            "484/484 [==============================] - 7s 13ms/step - loss: 1.0001 - accuracy: 0.8204\n",
            "Epoch 147/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.9861 - accuracy: 0.8238\n",
            "Epoch 148/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.9759 - accuracy: 0.8255\n",
            "Epoch 149/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.9642 - accuracy: 0.8256\n",
            "Epoch 150/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.9636 - accuracy: 0.8281\n",
            "Epoch 151/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.9734 - accuracy: 0.8233\n",
            "Epoch 152/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.9545 - accuracy: 0.8286\n",
            "Epoch 153/200\n",
            "484/484 [==============================] - 7s 15ms/step - loss: 0.9513 - accuracy: 0.8296\n",
            "Epoch 154/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.9361 - accuracy: 0.8324\n",
            "Epoch 155/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.9469 - accuracy: 0.8262\n",
            "Epoch 156/200\n",
            "484/484 [==============================] - 7s 13ms/step - loss: 0.9468 - accuracy: 0.8289\n",
            "Epoch 157/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.9426 - accuracy: 0.8312\n",
            "Epoch 158/200\n",
            "484/484 [==============================] - 7s 13ms/step - loss: 0.9432 - accuracy: 0.8291\n",
            "Epoch 159/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.9463 - accuracy: 0.8267\n",
            "Epoch 160/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.9282 - accuracy: 0.8300\n",
            "Epoch 161/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.9233 - accuracy: 0.8317\n",
            "Epoch 162/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.9228 - accuracy: 0.8304\n",
            "Epoch 163/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.9307 - accuracy: 0.8291\n",
            "Epoch 164/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.9257 - accuracy: 0.8310\n",
            "Epoch 165/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.9386 - accuracy: 0.8295\n",
            "Epoch 166/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.9212 - accuracy: 0.8297\n",
            "Epoch 167/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.9084 - accuracy: 0.8337\n",
            "Epoch 168/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.9039 - accuracy: 0.8340\n",
            "Epoch 169/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.9060 - accuracy: 0.8318\n",
            "Epoch 170/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.9009 - accuracy: 0.8311\n",
            "Epoch 171/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8985 - accuracy: 0.8328\n",
            "Epoch 172/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8970 - accuracy: 0.8351\n",
            "Epoch 173/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8995 - accuracy: 0.8322\n",
            "Epoch 174/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.9015 - accuracy: 0.8333\n",
            "Epoch 175/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8969 - accuracy: 0.8322\n",
            "Epoch 176/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8890 - accuracy: 0.8353\n",
            "Epoch 177/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8805 - accuracy: 0.8366\n",
            "Epoch 178/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8757 - accuracy: 0.8361\n",
            "Epoch 179/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8848 - accuracy: 0.8337\n",
            "Epoch 180/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8789 - accuracy: 0.8371\n",
            "Epoch 181/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8724 - accuracy: 0.8350\n",
            "Epoch 182/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.8808 - accuracy: 0.8364\n",
            "Epoch 183/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8756 - accuracy: 0.8346\n",
            "Epoch 184/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8765 - accuracy: 0.8342\n",
            "Epoch 185/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8785 - accuracy: 0.8335\n",
            "Epoch 186/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.8708 - accuracy: 0.8371\n",
            "Epoch 187/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8750 - accuracy: 0.8334\n",
            "Epoch 188/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8780 - accuracy: 0.8335\n",
            "Epoch 189/200\n",
            "484/484 [==============================] - 7s 13ms/step - loss: 0.8664 - accuracy: 0.8362\n",
            "Epoch 190/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8619 - accuracy: 0.8358\n",
            "Epoch 191/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8608 - accuracy: 0.8369\n",
            "Epoch 192/200\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.8544 - accuracy: 0.8383\n",
            "Epoch 193/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8528 - accuracy: 0.8371\n",
            "Epoch 194/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8644 - accuracy: 0.8328\n",
            "Epoch 195/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8504 - accuracy: 0.8375\n",
            "Epoch 196/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8660 - accuracy: 0.8324\n",
            "Epoch 197/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8598 - accuracy: 0.8343\n",
            "Epoch 198/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8575 - accuracy: 0.8332\n",
            "Epoch 199/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8542 - accuracy: 0.8357\n",
            "Epoch 200/200\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.8602 - accuracy: 0.8331\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqBw39FSI3s1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "cf44a7af-e695-408d-8174-f97c8a455ab7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDnUmW1Cb3dM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "28e5cf53-ab19-4616-e1fa-daf9f5fe87cc"
      },
      "source": [
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])\n",
        "\ttoken_list = pad_sequences(token_list, maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help me Obi Wan Kenobi, you're my only hope and take things gone free boast woe our thing i tell me thence day bright are store all store still told to decay seen wrinkles your true delight fight shall bear your parts age well did quickly steep pride ' to thee still not do me express'd thine bear thine despising thine own state still still eye most true delight told to wrong and bold compare told that vanish'd or bright still express'd express'd forgot survey see things store to please them you know their store i sing the day nor wrong of masonry dear delight now forgot did betray\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}